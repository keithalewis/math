<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="" xml:lang="">
<head>
  <meta charset="utf-8" />
  <meta name="generator" content="pandoc" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
  <meta name="author" content="Keith A. Lewis" />
  <meta name="dcterms.date" content="2025-01-30" />
  <title>Vector Space</title>
  <style>
    code{white-space: pre-wrap;}
    span.smallcaps{font-variant: small-caps;}
    div.columns{display: flex; gap: min(4vw, 1.5em);}
    div.column{flex: auto; overflow-x: auto;}
    div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
    /* The extra [class] is a hack that increases specificity enough to
       override a similar rule in reveal.js */
    ul.task-list[class]{list-style: none;}
    ul.task-list li input[type="checkbox"] {
      font-size: inherit;
      width: 0.8em;
      margin: 0 0.8em 0.2em -1.6em;
      vertical-align: middle;
    }
  </style>
  <link rel="stylesheet" href="math.css" />
  <script defer=""
  src="https://cdn.jsdelivr.net/npm/katex@0.12.0/dist/katex.min.js"></script>
  <script>document.addEventListener("DOMContentLoaded", function () {
 var mathElements = document.getElementsByClassName("math");
 var macros = [];
 for (var i = 0; i < mathElements.length; i++) {
  var texText = mathElements[i].firstChild;
  if (mathElements[i].tagName == "SPAN") {
   katex.render(texText.data, mathElements[i], {
    displayMode: mathElements[i].classList.contains('display'),
    throwOnError: false,
    macros: macros,
    fleqn: true
   });
}}});
  </script>
  <link rel="stylesheet"
  href="https://cdn.jsdelivr.net/npm/katex@0.12.0/dist/katex.min.css" />
</head>
<body>
<header id="title-block-header">
<h1 class="title">Vector Space</h1>
<p class="author">Keith A. Lewis</p>
<p class="date">January 30, 2025</p>
<div class="abstract">
<div class="abstract-title">Abstract</div>
A mathematical sweet spot
</div>
</header>
<nav id="TOC" role="doc-toc">
<ul>
<li><a href="#boldsymbolrn" id="toc-boldsymbolrn"><span
class="math inline">\boldsymbol{R}^n</span></a></li>
<li><a href="#axioms" id="toc-axioms">Axioms</a>
<ul>
<li><a href="#subspace" id="toc-subspace">Subspace</a></li>
<li><a href="#quotient" id="toc-quotient">Quotient</a></li>
<li><a href="#span" id="toc-span">Span</a></li>
<li><a href="#independent" id="toc-independent">Independent</a></li>
<li><a href="#basis" id="toc-basis">Basis</a></li>
</ul></li>
<li><a href="#linear-transformation"
id="toc-linear-transformation">Linear Transformation</a>
<ul>
<li><a href="#indexing" id="toc-indexing">Indexing</a></li>
<li><a href="#sum" id="toc-sum">Sum</a></li>
<li><a href="#invariant-subspace" id="toc-invariant-subspace">Invariant
Subspace</a></li>
</ul></li>
<li><a href="#dual" id="toc-dual">Dual</a></li>
</ul>
</nav>
<p>Many mathematical objects are sets with an algebraic structure.
Functions between sets with structure that preserve the structure are
<em>homomorphisms</em>. A homomorphism that is bijective (one-to-one and
onto) is an <em>isomorphism</em>. Two sets with structure are
<em>equivalent</em> if there is an isomorphism between them. In general,
it is difficult to determine when two sets with structure are
equivalent, but vector spaces are a mathematical sweet spot. Two vector
spaces are equivalent if and only if they have the same dimension.</p>
<p>A <em>linear operator</em> is homomorphism from one vector space to
another. Given two vector spaces, the set of all linear operators is
also a vector space. If the two vector spaces are equal then composition
defines a product making the set of <em>endomorphisms</em> into an
<em>algebra</em>. Two endomorphisms are equivalent in the algebra if and
only if they have the same <em>Jordan canonical form</em>.</p>
<section id="boldsymbolrn" class="level2">
<h2><span class="math inline">\boldsymbol{R}^n</span></h2>
<p>A list of real numbers <span class="math inline">x =
(x_1,\ldots,x_n)</span> is a vector. Given a natural number <span
class="math inline">n\in\boldsymbol{N}</span>, let <span
class="math inline">{\boldsymbol{R}^n = \{(x_1,\ldots,x_n)\mid
x_i\in\boldsymbol{R}, 1\le i\le n\}}</span> be the cartesian product of
<span class="math inline">n\in\boldsymbol{N}</span> copies of the real
numbers. Scalar multiplication and vector addition are defined by <span
class="math inline">{ax = xa = (ax_1,\ldots,ax_n)}</span> and <span
class="math inline">{x + y = (x_1 + y_1,\ldots,x_n + y_n)}</span>, for
<span class="math inline">{a\in\boldsymbol{R}}</span>, <span
class="math inline">{x,y\in\boldsymbol{R}^n}</span>.</p>
<p>The <em>standard basis</em> of <span
class="math inline">\boldsymbol{R}^n</span> is <span
class="math inline">{e_i\in\boldsymbol{R}^n}</span>, <span
class="math inline">{1\le i\le n}</span>, where <span
class="math inline">{e_i = (0,\ldots,1,\ldots,0)}</span> with all
elements <span class="math inline">0</span> except for a <span
class="math inline">1</span> in the <span
class="math inline">i</span>-th position. It is plausible that <span
class="math inline">{x = (x_1,\ldots,x_n) = x_1 e_1 + \cdots + x_n
e_n}</span> for <span class="math inline">{x\in\boldsymbol{R}^n}</span>,
but you should always be suspicious of arguments involving dots. We will
treat this more rigorously below.</p>
<p>The <em>inner product</em>, or <em>dot product</em>, of <span
class="math inline">x,y\in\boldsymbol{R}^n</span> is <span
class="math inline">(x,y) = x\cdot y = \sum_{1\le i\le n}x_i y_i</span>.
This is used to define a <em>norm</em> on <span
class="math inline">\boldsymbol{R}^n</span> by <span
class="math inline">\|x\| = \sqrt{x\cdot x}</span>.</p>
<p>The <em>Cauchy-Schwartz inequality</em> is <span
class="math inline">|(x, y)|\le\|x\|\|y\|</span>. Since <span
class="math inline">-1\le |(x, y)|/\|x\|\|y\|\le 1</span> there exists
<span class="math inline">\theta</span> between 0 and <span
class="math inline">2\pi</span> with <span
class="math inline">\cos\theta = (x, y)/\|x\|\|y\|</span>. This defines
the <em>angle</em> between two vectors.</p>
<p><strong>Exercise</strong> <em>Show <span class="math inline">\|x\|
\ge 0</span>, <span class="math inline">\|ax\| = |a|\|x\|</span>, and
<span class="math inline">\|x + y\| \le \|x\| + \|y\|</span>, for <span
class="math inline">a\in\boldsymbol{R}</span>, <span
class="math inline">x,y\in\boldsymbol{R}^n</span></em>.</p>
<p><em>Hint</em>: Use <span class="math inline">\|x + y\|^2 = \|x\|^2 +
2x\cdot y + \|y\|^2</span> and the Cauchy-Schwartz inequality.</p>
<p><strong>Exercise</strong>. <em>Show <span class="math inline">\|x\| =
0</span> implies <span class="math inline">x = 0</span>, <span
class="math inline">x\in\boldsymbol{R}^n</span></em>.</p>
<p><strong>Exercise</strong>. <em>Show equality holds in the
Cauchy-Schwartz inequality if and only if <span
class="math inline">x</span> is a scalar multiple of <span
class="math inline">y</span></em>.</p>
<p><em>Hint</em>: TODO Sid.</p>
<p>A norm defines a <em>metric</em> <span class="math inline">{d(x,y) =
\|x - y\|}</span></p>
<p><strong>Exercise</strong>. <em>Show <span class="math inline">d(x, y)
\le d(x,z) + d(z,y)</span>, <span
class="math inline">x,y,z\in\boldsymbol{R}^n</span> and <span
class="math inline">d(x,y) = 0</span> implies <span
class="math inline">x = y</span></em>.</p>
<p>A <em>Banach Space</em> is a vector space with a norm that is
<em>complete</em>.</p>
<p><strong>Exercise</strong>. <em>If <span
class="math inline">lim_{n\to\infty} \|x_n - x\| = 0</span> show <span
class="math inline">x\in\boldsymbol{R}^n</span></em>.</p>
<p><em>Hint</em>: The real numbers with absolute value norm is
complete.</p>
</section>
<section id="axioms" class="level2">
<h2>Axioms</h2>
<p>For <span class="math inline">x, y, z\in\boldsymbol{R}^n</span> and
<span class="math inline">a,b\in\boldsymbol{R}</span>,</p>
<p><strong>Exercise</strong>. <em>Show <span class="math inline">x + (y
+ z) = (x + y) + z</span></em>.</p>
<p><strong>Exercise</strong>. <em>Show <span class="math inline">x + y =
y + x</span></em>.</p>
<p><strong>Exercise</strong>. <em>Show <span
class="math inline">\boldsymbol{0}+ x = x</span> where <span
class="math inline">\boldsymbol{0}= (0,\ldots,0)</span></em>.</p>
<p><strong>Exercise</strong>. <em>Show <span class="math inline">x +
(-x) = \boldsymbol{0}</span> where <span class="math inline">(-x)_i =
-(x_i)</span>, for <span class="math inline">1\le i\le
n</span></em>.</p>
<p><strong>Exercise</strong>. <em>Show <span class="math inline">a(bx) =
(ab)x</span></em>.</p>
<p><strong>Exercise</strong>. <em>Show <span class="math inline">1x =
x</span></em>.</p>
<p><strong>Exercise</strong>. <em>Show <span class="math inline">a(x +
y) = ax + ay</span></em>.</p>
<p><strong>Exercise</strong>. <em>Show <span class="math inline">(a +
b)x = ax + bx</span></em>.</p>
<p><em>Hint</em>: Use the properties of real numbers.</p>
<p>The exercises are the axioms for an <em>abstract vector space</em>
with scalar multiplication <span
class="math inline">{\boldsymbol{R}\times V\to V}</span> where <span
class="math inline">{(a,x)\mapsto ax = xa}</span> and binary addition
<span class="math inline">{V\times V\to V}</span> where <span
class="math inline">{(x,y)\mapsto x + y}</span>.</p>
<p>Proofs involving only the abstract axioms are considered more
elegant.</p>
<p><strong>Exercise</strong>. <em>For any vector space <span
class="math inline">V</span> show <span class="math inline">{v + v =
v}</span> implies <span class="math inline">{v = \boldsymbol{0}}</span>
for all <span class="math inline">{v\in V}</span></em>.</p>
<details>
<summary>
Solution
</summary>
<span class="math display">
\begin{aligned}
v + v &amp;= v \\
    &amp;\quad\langle x = y\Rightarrow x + z = y + z\mid x\leftarrow v +
v,y\leftarrow v,z\leftarrow -v\rangle\\
(v + v) + (-v) &amp;= v + (-v) \\
    &amp;\quad\langle (x + y) + z = x + (y + z)\mid x\leftarrow v,
y\leftarrow v, z\leftarrow -v\rangle\\
v + (v + (-v)) &amp;= v + (-v) \\
    &amp;\quad\langle x + (-x) = \boldsymbol{0}\mid x\leftarrow v\text{
twice }\rangle\\
v + \boldsymbol{0}&amp;= \boldsymbol{0}\\
    &amp;\quad\langle x + \boldsymbol{0}= x\mid x\leftarrow v\rangle\\
v &amp;= \boldsymbol{0}
\end{aligned}
</span>
</details>
<p>A homomorphism <span class="math inline">T\colon V\to W</span> from a
vector space <span class="math inline">V</span> to a vector space <span
class="math inline">W</span> is a <em>linear operator</em>.</p>
<p><strong>Exercise</strong>. <em>If <span class="math inline">T</span>
is a linear operator then <span class="math inline">T\boldsymbol{0}=
\boldsymbol{0}</span></em>.</p>
<p><em>Hint</em>: Show <span class="math inline">T\boldsymbol{0}+
T\boldsymbol{0}= T\boldsymbol{0}</span> and use the previous exercise.
Note the <span class="math inline">\boldsymbol{0}</span>s on the left
hand side are the additive identity of <span
class="math inline">V</span> and the <span
class="math inline">\boldsymbol{0}</span> on the right hand side is the
additive identity of <span class="math inline">W</span>.</p>
<details>
<summary>
Solution
</summary>
Since <span class="math inline">{Tv + Tw = T(v + w)}</span> and <span
class="math inline">{\boldsymbol{0}+ v = v}</span> we have <span
class="math inline">{T\boldsymbol{0}+ T\boldsymbol{0}= T(\boldsymbol{0}+
\boldsymbol{0}) = T\boldsymbol{0}}</span>.
</details>
<p>The collection of all linear operators from a vector space <span
class="math inline">V</span> to a vector space <span
class="math inline">W</span> is denoted <span
class="math inline">\mathcal{L}(V,W)</span>. It is a vector space with
scalar multiplication and vector addition defined by <span
class="math inline">{(aT)v = a(Tv)}</span> and <span
class="math inline">{(T + U)v = Tv + Tv}</span> for <span
class="math inline">T\in\mathcal{L}(V,W)</span>, <span
class="math inline">a\in\boldsymbol{R}</span>, <span
class="math inline">v\in V</span>.</p>
<p><strong>Exercise</strong>. <em>Show linear operators form a vector
space</em>.</p>
<p>An important special case is when the range is the one-dimensional
vector space <span class="math inline">\boldsymbol{R}</span>. Define the
<em>dual</em> of the vector space <span class="math inline">V</span> by
<span class="math inline">V^* = \mathcal{L}(V,\boldsymbol{R})</span>. We
write the <em>dual pairing</em> using angle brackets <span
class="math inline">{\langle v,v^*\rangle = v^*v}</span> for <span
class="math inline">{v^*\in V^*}</span>, <span class="math inline">{v\in
V}</span>.</p>
<!--
If $T\colon V\to W$ is a linear transformation define its _adjoint_
${T^*\colon W^*\to V^*}$ by ${\langle v, T^*w^*\rangle = \langle Tv, w^*\rangle}$,
${v\in V}$, ${w^*\in W^*}$.
-->
<p>The set of all functions from a (possibly infinite) set <span
class="math inline">I</span> to the real numbers, <span
class="math inline">{\boldsymbol{R}^I = \{x\colon
I\to\boldsymbol{R}\}}</span>, is a vector space over <span
class="math inline">\boldsymbol{R}</span>. Scalar multiplication and
vector addition are defined pointwise: <span
class="math inline">{(ax)(i) = ax(i)}</span> and <span
class="math inline">{(x + y)(i) = x(i) + y(i)}</span> for <span
class="math inline">{i\in I}</span>. This generalizes <span
class="math inline">\boldsymbol{R}^n</span> when <span
class="math inline">{I = \{1,\ldots,n\}}</span>. We can identify <span
class="math inline">x\colon\{1,\ldots,n\}\to\boldsymbol{R}</span> with
<span class="math inline">(x_1,\ldots,x_n)</span> by <span
class="math inline">x(i) = x_i</span>, <span class="math inline">i\in
I</span>.</p>
<p><strong>Exercise</strong>. <em>Show <span
class="math inline">\boldsymbol{R}^I</span> satisfies the abstract
vector space axioms.</em></p>
<p>The <em>standard basis</em> <span
class="math inline">e_i\in\boldsymbol{R}^I</span>, <span
class="math inline">i\in I</span>, is defined by <span
class="math inline">e_i(j) = δ_{ij}</span>, <span
class="math inline">j\in I</span>, where <span
class="math inline">δ_{ij} = 1</span> if <span
class="math inline">i=j</span> and <span class="math inline">δ_{ij} =
0</span> if <span class="math inline">i\not= j</span> is the
<em>Kronecker delta</em>.</p>
<p><strong>Exercise</strong>. <em>Show if <span
class="math inline">I</span> is finite then <span class="math inline">v
= \sum_i v(i) e_i</span></em>.</p>
<p><em>Hint</em>. Show <span class="math inline">v(j) = (\sum_i v(i)
e_i)(j)</span> for <span class="math inline">j\in I</span>.</p>
<p>We define the <em>dual basis</em> <span
class="math inline">e_j^*\in(\boldsymbol{R}^I)^*</span> by <span
class="math inline">e_j^*e_i = \delta_{ij}</span>.</p>
<p><strong>Exercise</strong>. <em>Show if <span
class="math inline">I</span> is finite then <span
class="math inline">v^* = \sum_i v^*e_i e^*_i</span></em>.</p>
<p><em>Hint</em>. Consider <span class="math inline">v^*e_j</span>.</p>
<p>We omit the non-trivial result these axioms imply there exists a set
<span class="math inline">I</span> where <span
class="math inline">V</span> can be identified with <span
class="math inline">\boldsymbol{R}^I</span>. The cardinality of <span
class="math inline">I</span> is the <em>dimension</em> of <span
class="math inline">\boldsymbol{R}^I</span>.</p>
<section id="subspace" class="level3">
<h3>Subspace</h3>
<p>A subset <span class="math inline">U\subseteq V</span> of a vector
space <span class="math inline">V</span> is a <em>subspace</em> if <span
class="math inline">U</span> is also a vector space.</p>
<p><strong>Exercise</strong>. <em>Let <span class="math inline">U</span>
be a subset of <span class="math inline">V</span>. If <span
class="math inline">\boldsymbol{R}U\subseteq U</span> and <span
class="math inline">U + U\subseteq U</span> then <span
class="math inline">U</span> is a subspace of <span
class="math inline">V</span></em>.</p>
<p><em>Hint</em>. <span class="math inline">\boldsymbol{R}U = \{au\mid
a\in\boldsymbol{R}, u\in U\}</span> and <span class="math inline">U + U
= \{v + w\mid v\in U, w\in U\}</span>.</p>
<details>
<summary>
Solution
</summary>
If <span class="math inline">u\in U</span> and <span
class="math inline">a\in\boldsymbol{R}</span> then <span
class="math inline">au\in\boldsymbol{R}U\subseteq U</span>. If <span
class="math inline">v\in U</span> and <span class="math inline">w\in
U</span> then <span class="math inline">v + w\in U + U\subseteq
U</span>.
</details>
<p><strong>Exercise</strong>. <em>Show the intersection of two subspaces
is a subspace</em>.</p>
<p><em>Hint</em>. Show if <span class="math inline">v</span> is in the
intersection then <span class="math inline">av</span> is also in the
intersection for <span class="math inline">a\in\boldsymbol{R}</span> and
if <span class="math inline">u</span> and <span
class="math inline">w</span> are in the intersection then <span
class="math inline">u + w</span> is also in the intersection.</p>
<details>
<summary>
Solution
</summary>
If <span class="math inline">v\in U\cap V</span> then <span
class="math inline">au\in U</span> and <span class="math inline">av\in
V</span> so <span class="math inline">au\in U\cap V</span>. If <span
class="math inline">u,w\in U\cap V</span> then <span
class="math inline">u + w\in U</span> and <span class="math inline">u +
w\in V</span> so <span class="math inline">u + w\in U\cap V</span>.
</details>
<p><strong>Exercise</strong>. <em>Show the sum of two subspaces is a
subspace</em>.</p>
<p><em>Hint</em>. The sum of subspaces <span class="math inline">U,
W\subseteq V</span> is <span class="math inline">U + W = \{u + w\mid
u\in U, w\in W\}</span>.</p>
</section>
<section id="quotient" class="level3">
<h3>Quotient</h3>
<p>If <span class="math inline">U</span> is a subspace of <span
class="math inline">V</span> define <span class="math inline">{V/U = \{v
+ U\mid v\in V\}}</span>. Define scalar multiplication by <span
class="math inline">{a(v + U) = av + U}</span> and vector addition by
<span class="math inline">{(v + U) + (w + U) = (v + w) + U}</span>,
<span class="math inline">{a\in\boldsymbol{R}}</span>, <span
class="math inline">{v,w\in V}</span>.</p>
<p><strong>Exercise</strong>. <em>Show <span class="math inline">v + U =
w + U</span> if and only if <span class="math inline">v - w\in U</span>,
<span class="math inline">v,w\in V</span></em>.</p>
<p><strong>Exercise</strong>. <em>Show scalar multiplication and vector
multiplication are well-defined</em>.</p>
<p><em>Hint</em>: Show <span class="math inline">v + U = v&#39; +
U</span> implies <span class="math inline">a(v + U) = a(v&#39; +
U)</span>, and <span class="math inline">v + U = v&#39; + U</span>,
<span class="math inline">w + U = w&#39; + U</span>, imply <span
class="math inline">(v + w) + U = (v&#39; + w&#39;) + U</span>.</p>
<p><strong>Exercise</strong>. <em>Show <span
class="math inline">V/U</span> is a vector space with identity <span
class="math inline">\boldsymbol{0}+ U = U</span></em>.</p>
</section>
<section id="span" class="level3">
<h3>Span</h3>
<p>The <em>span</em> of a subset of a vector space is the smallest
subspace containing the subset.</p>
<p>A <em>linear combination</em> of vectors <span
class="math inline">v_i\in V</span>, <span class="math inline">i\in
I</span>, is a sum <span class="math inline">\sum_i a_i v_i</span> where
a finite number of <span class="math inline">a_i\in\boldsymbol{R}</span>
are non-zero. The <em>span</em> of <span
class="math inline">\{v_i\}_{i\in I}</span> is the set of all linear
combinations, <span class="math display">
\operatorname{span}\{v_i\} = \{\sum_i a_i v_i\mid
a_i\in\boldsymbol{R}\}.
</span></p>
<p><strong>Exercise</strong>. <em>Show the span is a vector
space</em>.</p>
<p><em>Hint</em>. Show if <span class="math inline">u</span> is in the
span then <span class="math inline">au</span> is also in the span for
<span class="math inline">a\in\boldsymbol{R}</span> and if <span
class="math inline">v</span> and <span class="math inline">w</span> are
in the span then <span class="math inline">v + w</span> is also in the
span.</p>
<details>
<summary>
Solution
</summary>
If <span class="math inline">u = \sum_j a_j v_j</span> then <span
class="math inline">{au = \sum_j a(a_j v_j) = \sum_j (aa_j)v_j}</span>
is in the span. If <span class="math inline">{v = \sum_j b_j v_j}</span>
and <span class="math inline">{w = \sum_j c_j v_j}</span> then <span
class="math inline">{v + w = \sum_j (b_j + c_j) v_j}</span> is in the
span.
</details>
</section>
<section id="independent" class="level3">
<h3>Independent</h3>
<p>A set of vectors <span class="math inline">\{v_i\}_{i\in I}</span>
are <em>independent</em> if for any finite sum <span
class="math inline">\sum a_i v_i = 0</span> implies <span
class="math inline">a_i = 0</span> for all <span
class="math inline">i</span>.</p>
<p><strong>Exercise</strong>. <em>If <span
class="math inline">\{v_i\}_{i\in I}</span> are independent and <span
class="math inline">{\sum_i a_i v_i = \sum_i b_i v_i}</span> then <span
class="math inline">{a_i = b_i}</span> for all <span
class="math inline">{i\in I}</span></em>.</p>
<p><em>Hint</em>: <span class="math inline">\sum_i (a_i - b_i) v_i =
\boldsymbol{0}</span>.</p>
<details>
<summary>
Solution
</summary>
If <span class="math inline">{\sum_i a_i v_i = \sum_i b_i v_i}</span>
then <span class="math inline">\boldsymbol{0}= \sum_i a_i v_i - \sum_i
b_i v_i = \sum_i (a_i - b_i)v_i</span> so <span class="math inline">a_i
- b_i = 0</span> for <span class="math inline">i\in I</span>.
</details>
<p><strong>Exercise</strong>. <em>If <span
class="math inline">\{v_i\}</span> are not independent then <span
class="math inline">v_j = \sum_{i\not= j} b_i v_i</span> for some <span
class="math inline">j\in I</span> and <span
class="math inline">b_i\in\boldsymbol{R}</span></em>.</p>
<p><em>Hint</em>: If <span class="math inline">\sum a_i v_i =
\boldsymbol{0}</span> and <span class="math inline">a_j\not= 0</span>
for some <span class="math inline">j\in I</span> then <span
class="math inline">a_j v_j = -\sum_{i\not=j} a_i v_i</span>.</p>
<details>
<summary>
Solution
</summary>
<span class="math inline">v_j = -\sum_{i\not=j} a_i/a_j v_i</span>.
</details>
</section>
<section id="basis" class="level3">
<h3>Basis</h3>
<p>A collection of vectors <span class="math inline">\{v_i\}_{i\in
I}</span>, <span class="math inline">v_i\in V</span>, is a
<em>basis</em> of <span class="math inline">V</span> if they are
independent and span <span class="math inline">V</span>. Since they span
<span class="math inline">V</span> every vector <span
class="math inline">v\in V</span> can be written as a linear combination
<span class="math inline">v = \sum_{i\in I} a_i v_i</span>. This shows
how to identify any vector space <span class="math inline">V</span> with
<span class="math inline">\boldsymbol{R}^I</span> given a basis <span
class="math inline">(v_i)_{i\in I}</span>.</p>
<p>The <em>dimension</em> of a vector space is the number of elements of
a basis. A vector space has many collections of vectors that are a basis
but every basis has the same number of vectors. This is not trivial to
prove.</p>
</section>
</section>
<section id="linear-transformation" class="level2">
<h2>Linear Transformation</h2>
<p>A <em>linear transformation</em>, or <em>linear operator</em>, is a
function <span class="math inline">T\colon V\to W</span>, where <span
class="math inline">V</span> and <span class="math inline">W</span> are
vector spaces that satisfies preserves the vector space structure: <span
class="math inline">{T(au + v) = aTu + Tv}</span>, <span
class="math inline">a\in\boldsymbol{R}</span>, <span
class="math inline">u,v\in V</span>. Note that the addition <span
class="math inline">{au + v}</span> occurs in <span
class="math inline">V</span> and <span class="math inline">{aTu +
Tv}</span> occurs in <span class="math inline">W</span>. The space of
all such linear transformations is denoted <span
class="math inline">\mathcal{L}(V,W)</span>.</p>
<p><strong>Exercise</strong>. <em>Show if <span
class="math inline">T</span> is a linear transformation then <span
class="math inline">T\boldsymbol{0}= \boldsymbol{0}</span></em>.</p>
<p><strong>Hint</strong>: Consider <span
class="math inline">T(\boldsymbol{0}+ \boldsymbol{0})</span> and <span
class="math inline">v + v = v</span> implies <span class="math inline">v
= \boldsymbol{0}</span>.</p>
<details>
<summary>
Solution
</summary>
<span class="math inline">T(\boldsymbol{0}+ \boldsymbol{0}) =
T(\boldsymbol{0}) + T(\boldsymbol{0})</span> and <span
class="math inline">T(\boldsymbol{0}+ \boldsymbol{0}) =
T(\boldsymbol{0})</span> so <span class="math inline">T(\boldsymbol{0})
= \boldsymbol{0}</span>.
</details>
<p><strong>Exercise</strong>. <em>Show <span class="math inline">T(av) =
aTv</span>, <span class="math inline">a\in\boldsymbol{R}</span>, <span
class="math inline">v\in V</span></em>.</p>
<details>
<summary>
Solution
</summary>
Using <span class="math inline">T(av + w) = aTv + Tw</span>, <span
class="math inline">T(av) = T(av + 0) = aTv + T0 = aTv + 0 = aTv</span>.
</details>
<p><strong>Exercise</strong>. <em>Show <span class="math inline">T(av +
bw) = aTv + bTw</span>, <span
class="math inline">a,b\in\boldsymbol{R}</span>, <span
class="math inline">v,w\in V</span></em>.</p>
<details>
<summary>
Solution
</summary>
<span class="math inline">T(av + bw) = aTv + T(bw) = aTv = bTw</span>.
</details>
<p>A linear transformation <span class="math inline">T\colon V\to
W</span> is <em>one-to-one</em>, or <em>injective</em>, if <span
class="math inline">Tu = Tv</span> implies <span class="math inline">u =
v</span>.</p>
<p><strong>Exercise</strong>. <em>Show if <span class="math inline">Tv =
\boldsymbol{0}</span> implies <span class="math inline">v =
\boldsymbol{0}</span> then <span class="math inline">T</span> is
one-to-one</em>.</p>
<p><em>Hint</em>. Use linearity.</p>
<details>
<summary>
Solution
</summary>
If <span class="math inline">Tu = Tv</span> then <span
class="math inline">T(u - v) = \boldsymbol{0}</span> so <span
class="math inline">u - v = \boldsymbol{0}</span> and <span
class="math inline">u = v</span>.
</details>
<p>Define the <em>kernel</em> of a linear transformation <span
class="math inline">\operatorname{ker}T = \{v\in V\mid Tv =
\boldsymbol{0}\}</span>.</p>
<p><strong>Exercise</strong>. <em>Show <span
class="math inline">\operatorname{ker}T</span> is a subspace</em>.</p>
<p><strong>Exercise</strong>. <em>Show <span
class="math inline">T</span> is one-to-one if and only if <span
class="math inline">\operatorname{ker}T =
\{\boldsymbol{0}\}</span></em>.</p>
<p>Define <span class="math inline">\pi_T\colon V\to
V/\operatorname{ker}T</span> by <span class="math inline">\pi_T v = v +
\operatorname{ker}T</span>.</p>
<p><strong>Exercise</strong>. <em>Show <span
class="math inline">\pi_T</span> is a well-defined linear
transformation</em>.</p>
<p>A linear transformation <span class="math inline">T\colon V\to
W</span> is <em>onto</em>, or <em>surjective</em>, if for every <span
class="math inline">w\in W</span> there exists <span
class="math inline">v\in V</span> with <span class="math inline">Tv =
w</span>.</p>
<p>Define the <em>range</em> of a linear transformation <span
class="math inline">{\operatorname{ran}T = TV = \{w\mid w = Tv\text{ for
some }v\in V\}}</span> and let <span class="math inline">\nu_T\colon
V/\operatorname{ker}T\to\operatorname{ran}T</span> by <span
class="math inline">\nu_T(v + \operatorname{ker}T) = Tv</span>.</p>
<p><strong>Exercise</strong> <em>Show <span
class="math inline">\nu_T</span> well-defined, one-to-one, and
onto</em>.</p>
<p>A linear transformation that is one-to-one and onto, or
<em>bijective</em>, is an <em>isomorphism</em>. If <span
class="math inline">T\colon V\to W</span> is an isomorphism then <span
class="math inline">V</span> and <span class="math inline">W</span> are
<em>isomorphic</em>, <span class="math inline">V\cong W</span>.</p>
<p><strong>Exercise</strong>. <em>Show if <span
class="math inline">T</span> is an isomorphism then <span
class="math inline">T^{-1}</span> is linear</em>.</p>
<p><strong>Exercise</strong>. <em>Show <span class="math inline">V\cong
W</span> is an equivalence relation</em>.</p>
<p><em>Hint</em>: This means <span class="math inline">V\cong V</span>,
<span class="math inline">V\cong W</span> implies <span
class="math inline">W\cong V</span>, and <span
class="math inline">V\cong W</span>, <span class="math inline">W\cong
U</span> implies <span class="math inline">V\cong U</span>.</p>
<details>
<summary>
Solution
</summary>
The identity transformation <span class="math inline">I\colon V\to
V</span> defined by <span class="math inline">I(v) = v</span> shows
<span class="math inline">V\cong V</span>. If <span
class="math inline">T\colon V\to W</span> is an isomorphism then its
inverse <span class="math inline">T^{-1}\colon W\to V</span> shows <span
class="math inline">W\cong V</span>. If <span
class="math inline">T\colon V\to W</span> and <span
class="math inline">S\colon W\to U</span> are isomorphisms then so is
<span class="math inline">ST</span> and <span class="math inline">V\cong
U</span>.
</details>
<p>The space of linear transformations <span
class="math inline">\mathcal{L}(V,W)</span> is also a vector space under
pointwise scalar multiplication <span class="math inline">{(aT)v =
a(Tv)}</span> pointwise addition <span class="math inline">{(T + S)v =
Tv + Sv}</span>, <span class="math inline">a\in\boldsymbol{R}</span>,
<span class="math inline">v,w\in V</span>. The space <span
class="math inline">\mathcal{L}(\boldsymbol{R}^n,\boldsymbol{R}^m)</span>
can be identified with <span class="math inline">\boldsymbol{R}^{n\times
m}</span>. If <span
class="math inline">{T\colon\boldsymbol{R}^n\to\boldsymbol{R}^m}</span>
then <span class="math inline">{Te_i = \sum_j t_{ij} e_j}</span> for
some <span class="math inline">t_{ij}\in\boldsymbol{R}</span>.</p>
<p><strong>Exercise</strong>. <em>If <span
class="math inline">T\colon\boldsymbol{R}^k\to\boldsymbol{R}^n</span>
and <span
class="math inline">S\colon\boldsymbol{R}^n\to\boldsymbol{R}^m</span>
then the composition <span class="math inline">U =
ST\colon\boldsymbol{R}^k\to\boldsymbol{R}^m</span>. Show <span
class="math inline">u_{ij} = \sum_k t_{ik} s_{kj}</span></em>.</p>
<details>
<summary>
Solution
</summary>
<span class="math inline">R(e_i) = ST(e_i)  = S(\sum_k t_{ik} e_k)  =
\sum_k t_{ik} Se_k  = \sum_k t_{ik} \sum_j s_{kj} e_j  = \sum_j \sum_k
t_{ik} s_{kj} e_j  = \sum_j u_{ij} e_j</span>
</details>
<p>Matrix multiplication is composition of linear transformations.</p>
<!--
Another way to see this is to use $A\times B\to C$ is isomorphic to
$A\to(B\to C)$ for any sets $A, B, C$. This is called _currying_ after Haskell Curry.
If $f\colon A\times B\to C$ define $f,\colon A\to(B\to C)$
by $(f,a)b = f(a,b)$.
If $g\colon A\to(B\to C)$ define $g`\colon A\times B\to C$
by $g`(a,b) = (ga)b$.

__Exercise__. _If $f\colon A\times B\to C$ show $(f,)` = f$
and if $g\colon A\to(B\to C)$ show $(g`), = g$_.

This shows a bijection???

We can identify $(I\to\RR)\to(J\to\RR)$ with $I\times J\to\RR$.
-->
<p>Let <span class="math inline">\mathcal{L}(V) =
\mathcal{L}(V,V)</span> be the space of linear transformations from a
vector space to itself. It is also an <em>algebra</em> with
multiplication defined by composition with identity <span
class="math inline">{I_V = I\colon V\to V}</span> defined by <span
class="math inline">{Iv = v}</span>, <span class="math inline">{v\in
V}</span>.</p>
<p><strong>Exercise</strong>. <em>Show <span class="math inline">IT =
TI</span> and <span class="math inline">T(U + V) = TU + TV</span>, <span
class="math inline">{T,U,V\in\mathcal{L}(V)}</span></em>.</p>
<section id="indexing" class="level3">
<h3>Indexing</h3>
<p>For every <em>change of index function</em> <span
class="math inline">s\colon I\to J</span> define <span
class="math inline">\circ s\colon
\boldsymbol{R}^J\to\boldsymbol{R}^I</span> define <span
class="math inline">\circ s v = vs\in\boldsymbol{R}^I</span>, for <span
class="math inline">v\in\boldsymbol{R}^J</span>.</p>
<p><strong>Exercise</strong>. <em>Show <span class="math inline">\circ
s</span> is a linear operator</em>.</p>
<p><em>Hint</em>: <span class="math inline">\circ s v(i) =
v(s(i))</span> for <span
class="math inline">v\in\boldsymbol{R}^J</span>.</p>
</section>
<section id="sum" class="level3">
<h3>Sum</h3>
<p>If <span class="math inline">U</span> and <span
class="math inline">W</span> are vector spaces define the <em>external
direct sum</em> <span class="math inline">U\oplus W = \{u\oplus w)\mid
u\in U, w\in W\}</span>, where <span class="math inline">u\oplus
w</span> is the pair <span class="math inline">(u,w)</span>. Define
scalar multiplication <span class="math inline">a(u\oplus w) =
(au)\oplus (aw)</span> and vector addition <span
class="math inline">(u\oplus w) + (u&#39;\oplus w&#39;) = (u +
u&#39;)\oplus (w + w&#39;)</span>.</p>
<p><strong>Exercise</strong>. <em>Show <span class="math inline">U\oplus
W</span> is a vector space</em>.</p>
<p>If <span class="math inline">U</span> and <span
class="math inline">W</span> are subspaces of the vector space <span
class="math inline">V</span> with <span class="math inline">U\cap W =
\{\boldsymbol{0}\}</span> then the <em>interal direct sum</em> <span
class="math inline">U + V\cong U\oplus V</span>.</p>
<p><strong>Exercise</strong>. <em>Show this!!!</em>.</p>
<p>Claim: <span class="math inline">V\cong U\oplus V/U</span>.</p>
<p>Define <span class="math inline">T\colon U\oplus V/U\to V</span> by
<span class="math inline">T(u\oplus v+W) = u + v</span>.</p>
<p>If <span class="math inline">U</span> is invariant for <span
class="math inline">T</span> then <span class="math inline">U</span> is
invariant for <span class="math inline">T - \lambda I</span>.</p>
<p><em>Hint</em>: If <span class="math inline">Tu = v</span>, <span
class="math inline">u,v\in U</span> then <span class="math inline">(T -
\lambda I)u\in U</span>.</p>
<p>If <span class="math inline">T\in\mathcal{L}(U,V)</span> define <span
class="math inline">\operatorname{graph}T = \{u\oplus Tu\mid u\in
U\}</span>.</p>
<p><strong>Exercise</strong>. <em>Show <span
class="math inline">T</span> is linear if and only if <span
class="math inline">\operatorname{graph}T</span> is a subspace</em>.</p>
</section>
<section id="invariant-subspace" class="level3">
<h3>Invariant Subspace</h3>
<p>An <em>invariant subspace</em> of a linear operator <span
class="math inline">T\colon V\to V</span> is a subspace <span
class="math inline">U\subseteq V</span> with <span
class="math inline">TU\subseteq U</span>. Similar to prime factorizaton
of numbers, invariant subspaces break down linear operators into smaller
pieces.</p>
<p><strong>Exercise</strong>. <em>If <span class="math inline">T\colon
V\to V</span> is a linear operator show <span
class="math inline">\operatorname{ker}T</span> and <span
class="math inline">\operatorname{ran}T</span> are invariant
subspaces</em>.</p>
<p>If <span class="math inline">U</span> is a 1-dimensional invariant
subspace spanned by <span class="math inline">e\in V</span> then <span
class="math inline">e</span> is an <em>eigenvector</em> and <span
class="math inline">Te = \lambda e</span> for some <span
class="math inline">\lambda\in\boldsymbol{R}</span>, the
<em>eigenvalue</em> corresponding to <span
class="math inline">u</span>.</p>
<p>If the eigenvectors of <span class="math inline">T</span> are
independent they and their corresponding eigenvalues determine <span
class="math inline">T</span>. Let <span
class="math inline">(e_i)</span>, <span
class="math inline">(\lambda_i)</span> be the eigenvectors and
corresponding eigenvalues. Every vector <span class="math inline">v\in
V</span> can be written <span class="math inline">v = \sum_i a_i
e_i</span> so <span class="math inline">Tv = \sum_i a_i Te_i = \sum_i
\lambda_i a_i v_i</span>. In this case we say <span
class="math inline">T</span> is <em>diagonalizable</em>. Using the
eigenvectors as a basis, <span class="math inline">t_{ij} = \lambda_i
δ_{ij}</span>.</p>
<p>If <span class="math inline">e</span> is an eigenvector with
eigenvalue <span class="math inline">\lambda</span> then <span
class="math inline">Te = \lambda e</span> so <span
class="math inline">(T - \lambda I)e = 0</span> and <span
class="math inline">e\in\operatorname{ker}(T - \lamda I)</span>. There
may be vectors that are not eigenvectors that belong to <span
class="math inline">\operatorname{ker}(T - \lambda I)</span>.</p>
<p><strong>Exercise</strong>. _If the matrix of <span
class="math inline">T</span> is <span class="math inline">[0, 1; 0,
0]</span> then</p>
<p><strong>Exercise</strong>. <em>If the eigenvectors of <span
class="math inline">T</span> form a basis then <span
class="math inline">(T-\lambda_1I)\cdots(T-\lambda_nI) =
0</span></em>.</p>
<p>The dimension of <span
class="math inline">\mathcal{L}(\boldsymbol{R}^n,\boldsymbol{R}^n)</span>
is <span class="math inline">n^2</span> so we know <span
class="math inline">I</span>, <span class="math inline">T</span>, <span
class="math inline">T^2</span>, , <span
class="math inline">T^{n^2}</span> must be linearly dependent so there
is a polynomial of order at most <span class="math inline">n^2</span>
with <span class="math inline">p(T) = 0</span>. If <span
class="math inline">T</span> is diagonalizable the above exercise shows
there is a polynomial of order <span class="math inline">n</span>
satisfying this. The Cayley-Hamilton states this is true for any <span
class="math inline">T</span> where <span class="math inline">p(\lambda)
= \det(T - \lambda I)</span>.</p>
</section>
</section>
<section id="dual" class="level2">
<h2>Dual</h2>
<p>The <em>dual</em> of a vector space is <span class="math inline">V^*
= \mathcal{L}(V,\boldsymbol{R})</span>, the space of <em>linear
functionals</em> on <span class="math inline">V</span>. Define the
<em>dual pairing</em> by <span class="math inline">\langle v,v^*\rangle
= v^*(v)</span> for <span class="math inline">v\in V</span> and <span
class="math inline">v^*\in V^*</span>.</p>
<p>If <span class="math inline">V = \boldsymbol{R}^n</span> we can
identify <span class="math inline">V^*</span> with <span
class="math inline">\boldsymbol{R}^n</span> using the standard basis.
Define the <em>dual basis</em> <span
class="math inline">e_j^*\colon\boldsymbol{R}^n\to\boldsymbol{R}</span>
by <span class="math inline">e_j^*(e_k) = δ_{jk}</span>.</p>
<p><strong>Exercise</strong>. <em>Show <span class="math inline">v =
\sum_j e_j^*(v) e_j</span>, <span
class="math inline">v\in\boldsymbol{R}^n</span></em>.</p>
<details>
<summary>
Solution
</summary>
If <span class="math inline">v = \sum_j v_j e_j</span> then <span
class="math inline">e_i^*(v) = v_i</span>.
</details>
<p><strong>Exercise</strong>. <em>Show <span class="math inline">v^* =
\sum_j v^*(e_j) e_j^*</span>, <span
class="math inline">v^*\in(\boldsymbol{R}^n)^*</span></em>.</p>
<details>
<summary>
Solution
</summary>
If <span class="math inline">v^* = \sum_j v_j e_j^*</span> then <span
class="math inline">e_i^*(v) = v_i</span>.
</details>
<p>If <span class="math inline">V</span> has <em>any</em> basis <span
class="math inline">e_j</span> then every <span class="math inline">v\in
V</span> can be written <span class="math inline">v = \sum v_j
e_j</span> for some <span
class="math inline">v_j\in\boldsymbol{R}</span>. Define the <em>dual
basis</em> <span class="math inline">e_j^*\colon V\to\boldsymbol{R}\in
V^*</span> by <span class="math inline">e_j^*(v) = v_j</span>. The map
<span class="math inline">V\to V^*</span> by <span class="math inline">v
= \sum_j v_j e_j\mapsto \sum v_j e_j^* = v^*</span> is one-to-one and
onto (an <em>isomorphism</em>).</p>
<p>Functions are vectors. They can be added and scalar multiplication
satisfies the distributed law. Integration is a linear functional on a
space of functions. Given a set <span class="math inline">\Omega</span>
let <span class="math inline">B(\Omega) =
\{f\colon\Omega\to\boldsymbol{R}: \|f\| =
\sup_{\omega\in\Omega}|f(\omega)| &lt; \infty\}</span>.</p>
<p>If <span class="math inline">L\colon
B(\Omega)\to\boldsymbol{R}</span> is a linear functional define <span
class="math inline">\lambda(E) = L(1_E)</span> for <span
class="math inline">E\subseteq\Omega</span>.</p>
<p><strong>Exercise</strong>. <em>If <span
class="math inline">E,F\subseteq\Omega</span> are disjoint the <span
class="math inline">1_{E\cup F} = 1_E + 1_F</span></em>.</p>
<p>This shows <span class="math inline">\lambda(E\cup F) = \lambda(E) +
\lambda(F)</span> if <span class="math inline">E\cap F=\emptyset</span>.
Since <span class="math inline">1_\emptyset = 0</span> we have <span
class="math inline">\lambda(\emptyset) = 0</span> so <span
class="math inline">\lambda</span> is a (finitely additive) measure.</p>
<p>Given a finitely additive measure <span
class="math inline">\lambda</span> on subsets of <span
class="math inline">\Omega</span> define a linear functional <span
class="math inline">L\colon B(\Omega)\to\boldsymbol{R}</span> by <span
class="math inline">L(\sum_i a_i 1_{E_i}) = \sum_i a_i
\lambda(E_i)</span>.</p>
<p><strong>Exercise</strong>. <em>Show this is well-defined</em>.</p>
<p><em>Hint</em>: <span class="math inline">\sum_i a_i 1_{A_i} = \sum_j
b_j 1_{B_j}</span> where <span class="math inline">(B_j)</span> are
pairwise disjoint. Note <span class="math inline">1_A + 1_B =
1_{A\setminus B} + 1_{A\cap B} + 1_{B\setminus A}</span> is a sum of
pairwise disjoint sets.</p>
<p><strong>Exercise</strong>. <em>Given <span class="math inline">f\in
B(Ω)</span> and <span class="math inline">ε &gt; 0</span> show there
exist a finite number of <span
class="math inline">a_i\in\boldsymbol{R}</span> and <span
class="math inline">A_i\subseteq Ω</span> with <span
class="math inline">\|f - \sum_i a_i 1_{A_i}\| &lt; ε</span></em>.</p>
<p>This shows the linear functional can be extended to <span
class="math inline">B(\Omega)</span> and <span
class="math inline">B(\Omega)^*</span> is isomorphic to the space of
finitely additive measures on <span class="math inline">\Omega</span>,
<span class="math inline">ba(\Omega)</span>.</p>
<p>If <span class="math inline">\Omega</span> has a sufficiently rich
topology (e.g., compact and Hausdorff) then <span
class="math inline">C(\Omega)^*</span> can be identfied with the space
of countably additive Borel measures on <span
class="math inline">\Omega</span>, <span
class="math inline">M(\Omega)</span>. If <span
class="math inline">\mu\in M(\Omega)</span> define <span
class="math inline">L^p(\mu) = \{f\colon\Omega\to\boldsymbol{R}:
\int_\Omega |f|^p\,d\mu &lt; \infty\}</span>. It is true that <span
class="math inline">L^p(\mu)^*\cong L^q(\mu)</span> where <span
class="math inline">1/p + 1/q = 1</span> and <span class="math inline">p
&gt; 1</span>. It is not true that <span
class="math inline">L^\infty(\mu)^* \cong L^1(\mu)</span> in general.
Proving these claims is non-trivial.</p>
<!--

## Grassmann

For $I \subset V$ let $I\colon I\to V$ be injective.

Define $\vee I$ to be the span of $I$.

$t\colon I\to J$. $T\colon\RR^J\to\RR^I$.
$v\colon J\to\RR$ mapsto $Tv\colon I\to\RR$ by $Tv(i) = v(t(i)$.

$f\colon A\to B$

$\circ f\colon C^B\to C^A$ by $(\circ f)g = gf$.

$f\circ\colon A^C\to B^C$ by $(f\circ)h = fh$.

A function $f\colon I\to J$ determines a linear transformation
$F\colon\RR^J\to\RR^I$.

$I^n\to\RR$.

$d_i\colon I^n\to I^n\setminus\{i\}$

$\partial\colon I^n\to\RR^{I^{n-1}}$.

## Heisenberg

Werner Heisenberg rediscovered matrix multiplication by considering
orbital levels of the hydrogen atom. If $e_{ij}$ represents a jump
from level $i$ to level $j$, he posited
$e_{ij}e_{kl} = e_{il}$ if $j = k$ and equals $e_{ij}e_{kl} = 0$ if $j\not= k$. [@cite Hei]
An electron can jump from $i$ to $j$, then $j$ to $l$, but not
from $i$ to $j$, then $k$ to $l$ if $k\not= j$.

__Exercise__. _If $S = \sum_{i,j}s_{ij}e_{ij}$ and $T = \sum_{k,l} t_{kl}e_{kl}$ show
$TS = \sum_{i,j} (\sum_k t_{ik} s_{kj}) e_{ij}$_.

<details><summary>Solution</summary>
$$
\begin{aligned}
TS &= (\sum_{kl} t_{kl}e_{kl})(\sum_{ij}s_{ij}e_{ij}) \\
&= \sum_{ij} \sum_{kl} s_{ij} t_{kl} e_{ij}e_{kl} \\
&= \sum_{ij} \sum_{kl} s_{ij} t_{kl} e_{il}\delta_{jk} \\
&= \sum_{ij} \sum_k s_{ik} t_{kl} e_{il} \\
\end{aligned}
$$
</details>

The _kernel_ of a linear transformation $T\colon V\to W$ is
$\ker T = \{v\in V\mid Tv = 0\}\subseteq V$.

__Exercise__. _The kernel of a linear transformation is a subspace_.

_Hint_: $T(av + w) = aTv + Tw = 0$ for $a\in\RR$, $v,w\in \ker T$.

__Exercise__. _$T$ is one-to-one if and only if $\ker T = \{0\}$_.

_Hint_: Consider $T(v - v')$.

The _range_ of a linear transformation $T\colon V\to W$ is
$\ran T = \{Tv\mid v\in V\}\subseteq W$.

__Exercise__. _The range of a linear transformation is a subspace_.

_Hint_: $aTv + Tw = T(av + w)\in\ran T$.

If $\ran T = W$ then $T$ is _onto_, or _surjective_.

Every linear transformation $T\colon V\to W$ factors through the quotient space $V/\ker T$.
Define $π\colon V\to V/\ker T$ by $πv = v + \ker T$.

__Exercise__. _Show $π$ is a surjective linear transformation_.

Define $ν\colon V/\ker T\to\ran T$ by $ν(v + \ker T) = Tv$.

__Exercise__. _Show $ν$ is a well-defined injective linear transformation_.

_Hint_: Start by showing it is well-defined; if $v + \ker T = v' + \ker T$ then $Tv = Tv'$, $v,v'\in V$.

<details>
<summary>Solution</summary>
Since $v + \ker T = v' + \ker T$ if and only if $v - v'\in\ker T$ we have
$T(v - v') = 0$ so $Tv = Tv'$ and $ν$ is well-defined.
If $Tv = Tv'$ then $v - v'\in\ker T$ so $v + \ker T = v' + \ker T$
showing $ν$ is injective.
</details>


### Quotient

If $U$ is a subspace of $V$ and $v\in V$ define the _coset_ of $U$ containing $v$
by $v + U = \{v + u\mid u\in U\}$. Subspaces factor vector spaces into smaller vector spaces.

__Exercise__. _Show $v\in v+U$ for $v\in V$_.

_Hint_: $U$ is a vector space so $0\in U$.

__Exercise__. _Show $u + U = U$ if and only if $u\in U$_.

<details>
<summary>Solution</summary>
If $u + U = U$ then $u + u' = u''$ for some $u',u''\in U$
so $u = u'' - u'\in U$.

If $u\in U$ then $u + u'\in U$ for all $u'\in U$ so $u + U \subseteq U$
and if $u'\in U$ then $u' = u + (u' - u)\in u + U$ so $U\subseteq u + U$.
</details>

__Exercise__. _Show $v + U = w + U$ if and only if $v - w\in U$_.

<details>
<summary>Solution</summary>
If $v + U = w + U$ then $v + u = w + u'$ for some $u,u'\in U$
so $v - w = u' - u\in U$.

If $v - w\in U$ then $v - w = u$ for some $u\in U$
so $v + U = w + u + U = w + U$.
</details>

__Exercise__. _Show $v\cong_U w$ if and only if $v + U = w + U$ is
an equivalence relation_.

_Hint_: Show $v\cong v$ (reflexive), $v\cong w$ implies $w\cong v$ (symmetric), and
$v\cong w$ and $w\cong x$ implies $v\cong x$ (transitive).

The _quotient space_ $V/U = \{v + U\mid v\in V\}$ is a vector
space with scalar multiplication $a(v + U) = av + U$ and
addition $(v + U) + (w + U) = (v + w) + U$.

__Exercise__. _Show $v + U = w + U$ implies $av + U = aw + U$, $a\in\RR$, $v,w\in V$_.

_Hint_: $av - aw\in U$.

<details>
<summary>Solution</summary>
If $v + U = w + U$ then $v - w\in U$, so $a(v - w)\in U$ and $av + U = aw + U$.
</details>

__Exercise__. _Show $v + U = v' + U$ and $w + U = w' + U$ implies
$v + u + U = v' + w' + U$, $v,v',w,w'\in V$_.

_Hint_: $v - v', w - w'\in U$.

The last two exercises show scalar multiplication and addition are well-defined in $V/U$.

__Exercise__. _Show $(u + U) + (v + U) = (v + U) + (u + U)$ and
$a((u + U) + (v + U)) = a(u + U) + a(v + U)$_.

This shows addition is commutative and scalar multiplication distributes over addition,
hence the quotient space $V/U$ is a vector space where
the cosets are the vectors. A subspace $U$ and the quotient space $V/U$
determine $V$ up to isomorphism, but that requires more machinery.

-->
<!--
$T\colon U\to V$

$0\to\ker T\to U\to \ran T\to V\to 0$

$0\to U\to V\to V/U\to 0$.
-->
<!--
## Norm

A _norm_ on a vector space is a function $\|\cdot\|\colon V\to[0,\infty)$ with
$\|av\| = |a|\|v\|$, $\|v + w\| \le \|v\| + \|w\|$, $a\in\RR$, $v,w\in V$,
and $\|v\| = 0$ implies $v = 0$.

If $V=\CC^n$ then $\|v\|_\infty = \max_i |v_i|$ and $\|v\|_p = (\sum_i |v_i|^p)^{1/p}$
are the _sup norm_ and $p$-_norm_, $p\ge 1$.

__Exercise__. _Show $\lim_{p\to\infty}\|v\|_p = \|v\|_\infty$_.

If $T\colon V\to W$ is a linear transformation between normed vector spaces then
the _operator norm_ is $\|T\| = \sup_{\|v\|\le 1}\|Tv\|$.

__Exercise__. _Show $\|aT\| = |a|\|T\|$, $\|T + S\|\le \|T\| + \|S\|$ and $\|T\| = 0$ implies $T = 0$,
$a\in\RR$, $T,S\in\LL(V,W)$_.

## Inner Product

An _inner product_ on a vector space is a bilinear function $V\times V\to\RR$.
The pair $(u,v)$ is sent to $v\cdot w$, $v, w\in V$. The inner product satisfies
$v\cdot v \ge 0$ and $v\cdot v = 0$ implies $v = 0$.

__Exercise__. _Show $\|v\| = v\cdot v$ is a norm_.

__Theorem__ (Cauchy-Schwartz) _$|u\cdot v| \le \|u\| \|v\|$ and equality
holds if and only if $u$ and $v$ are colinear_.

_Proof_. Since $0\le\|au - v\|^2 = a^2\|u\|^2 - 2au\cdot v + \|v\|^2$
the discriminat $|u\cdot v|^2 - \|u\|^2 \|v\|^2\ge 0$. The discriminant
is 0 if and only if $au - v = 0$.

## Spectrum

If $V$ is a finite dimensional normed space over $\CC$ then every operator $T\colon V\to V$ has
and eigenvector.

The _spectrum_, $σ(T)$, of a linear operator $T\colon V\to V$ is the set of all $\lambda\in\CC$
such that $\ker(T - \lambdaI)$ is not invertable. The _spectral radius_ is
$ρ(T) = \max\{|\lambda|\mid \lambda\in σ(T)\}$.

__Exercise__. _Show if $V$ is finite dimensional then the spectrum is the set of eigenvalues_.

_Hint_: $\ker(T - \lambdaI)\neq 0$ if and only if $Te = \lambdae$ for some $e\in V$.

Define $E_\lambda = \ker(T - \lambdaI)$.

__Exercise__. _Show $E_\lambda\cap E_μ = 0$ if $\lambda\ne μ$_.

__Exercise__. _Show $\sum_{\lambda\in σ(T)} E_\lambda = V$_.

Define the _multiplicity_ of $\lambda\in\CC$ by $m(\lambda) = \dim\ker(T - \lambdaI)$.

__Exercise__. _Show there exists $e\in V$ with $(T - \lambdaI)^ke\neq 0$ for $0\le k < m(\lambda)$
and $(T - \lambdaI)^{m(\lambda)}e = 0$_.

### Adjoint

The _adjoint_ of a linear operator $T\colon V\to W$ is $T^*\colon W^*\to V^*$ defined
by $\langle v, T^* w\rangle = \langle Tv, w^*\rangle$, $v\in V$, $w^*\in W^*$.

## Fréchet Derivative

If $F\colon X\to Y$ is a function between normed vector spaces the _Fréchet_ derivative
$DF\colon X\to\LL(X,Y)$ is defined by
$$
    F(x + h) - F(x) = DF(x)h + o(\|h\|).
$$

Recall $F(x) = G(x) + o(\|h\|)$ means $\lim_{\|h\|\to 0} \|F(x) - G(x)\|/\|h\| = 0$.

__Exercise__. _If $F(x) = x^2$ where $x$ is a square matrix show $DF(x) = L_x + R_x$ where
$L_xy = xy$ and $R_xy = yx$_.

A suggestive way to write this is $D(x^2) = x(Dx) + (Dx)x$.

_Hint_: $(x + h)^2 = x^2 + xh + hx + h^2$ and $h^2 = o(\|h\|)$.

<details><summary>Solution</summary>
Since $(x + h)^2 = xx + xh + hx + hh$ and $\|h^2\| = o(\|h\})$ we have
$D(x^2)h = L_x h + R_x h$.
</details>

__Exercise__. _If $F(x) = x^n$ where $x$ is a square matrix and $n\in\NN$ show
$DF(x) = \sum_{i=0}^{n-1} L_x^{n-i-1}R_x^{i}$_.

_Hint_: What are the terms in $(x + h)^n$ containing exactly one $h$?

__Exercise__. _If $F\colon\RR^n\to\RR$ is
$F(x) = \|x\|^p$ show $DF(x) = p\|x\|^{p-2}x^*$._

_Hint_. Show $D\|x\|^2 = 2x^*$ and note $\|x\|^p = (\|x\|^2)^{p/2}$.
By the chain rule $D\|x\|^p = (p/2)\|x\|^{2(p/2 - 1)}2x^* = p\|x\|^{p - 2}x^*$.

-->
<!--
For example, a _semigroup_ is a set $S$ and binary operation ${m\colon S\times S\to S}$
that is associative: ${m(a,m(b,c)) = m(m(a,b),c)}$ for ${a,b,c\in S}$,
or ${a(bc) = (ab)c}$ if we write $ab$ for $m(a,b)$.
While this may seem trivial, is allows us to write $abc$ without parentheses.
This is the foundation of [MapReduce](https://en.wikipedia.org/wiki/MapReduce).

We can add an _identity_ $e$, not in the semigroup $S$, that satisfies
${es = s = se}$ for all $s\in S$ to turn a semigroup into a monoid
${M = S\cup\{e\}}$.

__Exercise__. _Show ${a(bc) = (ab)c}$ for ${a,b,c\in M}$_.

_Hint_: There are seven boring cases when $a$, $b$, and $c$ are $e$.

A _monoid_ is a semigroup with an identity for the binary operation.
The identity is unique.

__Exercise__. _If $M$ is a monoid and $e'\in M$ satisfies $e'm = m = me'$, $m\in M$, then $e' = e$_.

<details>
<summary>Solution</summary>
$e' = ee' = e$
</details>

__Exercise__. _Show $\max\{a,b\}$, $a,b\in\RR$ is a monoid with
identity $-\infty$_.

_Hint_: $-\infty < a$ for all $a\in\RR$.

__Exercise__. _Show $\min\{a,b\}$, $a,b\in\RR$ is a monoid with
identity $+\infty$_.

_Hint_: $\infty > a$ for all $a\in\RR$.

__Exercise__. _Show string concatenation is a monoid with
identity the empty string_.

The _Kleen star_ of a set is the union of the cartesian product of ${n\in\NN}$ copies of of the set.
If $M$ is a monoid 
where ${M^0 = \{e\}}$ and ${M^n = \{(m_1,\ldots,m_n)\mid m_j\in M, 1\le j\le n\}}$.
Define _fold_ ${f\colon M^*\to M}$ by ${f(e) = e}$ and ${f((m_1,\ldots,m_n)) = m_1\cdots m_n}$.
-->
</section>
</body>
</html>
