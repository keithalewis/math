<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="" xml:lang="">
<head>
  <meta charset="utf-8" />
  <meta name="generator" content="pandoc" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
  <meta name="author" content="Keith A. Lewis" />
  <meta name="dcterms.date" content="2025-10-18" />
  <title>Large Language Models</title>
  <style>
    code{white-space: pre-wrap;}
    span.smallcaps{font-variant: small-caps;}
    div.columns{display: flex; gap: min(4vw, 1.5em);}
    div.column{flex: auto; overflow-x: auto;}
    div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
    /* The extra [class] is a hack that increases specificity enough to
       override a similar rule in reveal.js */
    ul.task-list[class]{list-style: none;}
    ul.task-list li input[type="checkbox"] {
      font-size: inherit;
      width: 0.8em;
      margin: 0 0.8em 0.2em -1.6em;
      vertical-align: middle;
    }
  </style>
  <link rel="stylesheet" href="math.css" />
</head>
<body>
<header id="title-block-header">
<h1 class="title">Large Language Models</h1>
<p class="author">Keith A. Lewis</p>
<p class="date">October 18, 2025</p>
</header>
<p>https://github.com/karpathy/llm.c</p>
<p>A large language model is a function. Given a sequence of characters
it returns a sequence of characters. How does it do that?</p>
<p>It takes training data consisting of “correct” answers and
interpolates.</p>
<p>Machine learning began in … with … perceptrons. They were modelled
after neurons in the brain. Given a set of inputs they would either fire
or not.</p>
<p>The best prompt is “yes”. It will clue you in to the current context
of the LLM you are using at the moment. Use the output to detect what it
is <em>not</em> telling you.</p>
<p>A LLM is a function from an input string <em>prompt</em> and a
<em>context</em> to an <em>output</em> string. So called “prompt
engineering” is really about context engineering.</p>
</body>
</html>
