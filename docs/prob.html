<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="" xml:lang="">
<head>
  <meta charset="utf-8" />
  <meta name="generator" content="pandoc" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
  <meta name="author" content="Keith A. Lewis" />
  <title>Probability</title>
  <style>
    code{white-space: pre-wrap;}
    span.smallcaps{font-variant: small-caps;}
    span.underline{text-decoration: underline;}
    div.column{display: inline-block; vertical-align: top; width: 50%;}
    div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
    ul.task-list{list-style: none;}
  </style>
  <link rel="stylesheet" href="math.css" />
  <script src="https://cdn.jsdelivr.net/npm/katex@0.12.0/dist/katex.min.js"></script>
  <script>document.addEventListener("DOMContentLoaded", function () {
   var mathElements = document.getElementsByClassName("math");
   for (var i = 0; i < mathElements.length; i++) {
    var texText = mathElements[i].firstChild;
    if (mathElements[i].tagName == "SPAN") {
     katex.render(texText.data, mathElements[i], {
      displayMode: mathElements[i].classList.contains('display'),
      throwOnError: false,
      fleqn: true
     });
  }}});
  </script>
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.12.0/dist/katex.min.css" />
  <!--[if lt IE 9]>
    <script src="//cdnjs.cloudflare.com/ajax/libs/html5shiv/3.7.3/html5shiv-printshiv.min.js"></script>
  <![endif]-->
  <link rel="preconnect" href="https://fonts.gstatic.com">
  <link href="https://fonts.googleapis.com/css2?family=Literata:wght@300&display=swap" rel="stylesheet"> 
</head>
<body>
<header id="title-block-header">
<h1 class="title">Probability</h1>
<p class="author">Keith A. Lewis</p>
</header>
<h1 id="probability-theory">Probability Theory</h1>
<p>In order to understand statistics one must first understand <em>probability theory</em>.</p>
<h2 id="chevalier-de-méré">Chevalier de Méré</h2>
<p>A cubical die has six faces: <span class="math inline">⚀</span>, <span class="math inline">⚁</span>, <span class="math inline">⚂</span>, <span class="math inline">⚃</span>, <span class="math inline">⚄</span>, and <span class="math inline">⚅</span>. Each time a die is rolled the top face is the result of the roll. If the die is <em>fair</em> each face has an equal probability of occuring. The probability of rolling a <span class="math inline">⚅</span> in one roll is <span class="math inline">1/6</span>.</p>
<p>If a die is rolled twice then a <span class="math inline">⚅</span> occurs in exacty <span class="math inline">11 = 6 + 6 - 1</span> of the <span class="math inline">36 = 6^2</span> possible outcomes.<a href="#fn1" class="footnote-ref" id="fnref1" role="doc-noteref"><sup>1</sup></a> In <span class="math inline">6</span> cases it occurs on the first roll and in <span class="math inline">6</span> cases it occurs on the second roll but rolling <span class="math inline">⚅</span> twice is included in both the first and second cases and should only be counted once. The probability of rolling a <span class="math inline">⚅</span> in two rolls is <span class="math inline">11/36</span>.</p>
<p>If a die is rolled three times then the number of cases involving a <span class="math inline">⚅</span> in the <span class="math inline">216 = 6^3</span> possible outcomes is a more difficult counting problem. It is easier to count the number of cases where a <span class="math inline">⚅</span> does <strong>not</strong> occur: <span class="math inline">125 = 5^3</span>. The number of times <span class="math inline">⚅</span> <strong>does</strong> show up is therefor $91 = 216 - 125. The probability of rolling a <span class="math inline">⚅</span> in three rolls is <span class="math inline">91/216</span>. Note this can be used for the solution of the two roll case: <span class="math inline">11 = 36 - 25</span>. It is not a coincidence that <span class="math inline">91 = 3\times 6^2 - 3\times 6 + 1\times 1</span>. This is closely related to the formula <span class="math inline">(6 - 1)^3 = 6^3 - 3\times 6^2 + 3\times 6 - 1</span>.</p>
<p>If a die is rolled <span class="math inline">n</span> times then the number cases involving a <span class="math inline">⚅</span> is <span class="math inline">6^n - 5^n</span>. The <em>probability</em> of this happening is <span class="math inline">(6^n - 5^n)/6^n = 1 - (5/6)^n</span>. Note that this tends to <span class="math inline">1</span> as <span class="math inline">n</span> tends to infinity; you will eventually roll a <span class="math inline">⚅</span> if you roll long enough.</p>
<p>Chevalier de Méré was concerned with the problem of how to divide the wagers if the game was interupted part way thorough. (Vingt-deux, voilà les flics!) The initial odds are <span class="math inline">91</span> will get you <span class="math inline">125</span> in the three roll game. If the first roll is not a <span class="math inline">⚅</span> the odds of winning went down since there are only two rolls remaining to get a <span class="math inline">⚅</span>. If the game stops after the first roll how should the bet be fairly divided?</p>
<p>Antoine Gombaud (his real name) asked his salon friends Blaise Pascal and Pierre de Fermat about this puzzle. They came up with a complete solution of how to count with partial information.</p>
<p>Read on.</p>
<h2 id="probabilty-space">Probabilty Space</h2>
<p>A <em>sample space</em> is a set of <em>outcomes</em>. Subsets of a sample space are <em>events</em>. A <em>probability measure</em> assigns a number between 0 and 1 to events that represents a <em>degree of belief</em> an outcome will belong to the event. <em>Partial information</em> is modeled by a <em>partition</em> of the sample space.</p>
<h3 id="sample-space">Sample Space</h3>
<p>A <em>sample space</em> is a set of what can happen in a probability model. An <em>outcome</em> is an element of a sample space. An <em>event</em> is a subset of a sample space.</p>
<p>A sample space for flipping a coin can be modeled by the set <span class="math inline">\{H,T\}</span> where the outcome <span class="math inline">H</span> indicates heads and <span class="math inline">T</span> indicates tails. Of course any two element set could be used for this.</p>
<p>A sample space for flipping a coin twice can be modeled by the set <span class="math inline">\{HH, HT, TH, TT\}</span> where each outcome specifies the individual outcomes of the first and second flip. The event ‘the first flip was heads’ is the subset <span class="math inline">\{HH, HT\}</span>. The partition <span class="math inline">\{\{HH, HT\},\{TH, TT\}\}</span> represents the partial information of knowing the outcome of the first coin flip. The first event in the partition indicates the first flip was heads. The second event in the partition indicates the first flip was tails.</p>
<!--
heads or tails as the outcome of a coin toss, the integers from 1 to
6 as the outcomes of rolling a single die, the set of all sequences of
not more than 280 characters as a model of possible Twitter tweets.

Assuming the characters are upper and lower case letters, space, and
3 punctuation marks then there are $30^280$ possible messages. This
is approximately $10^1374$. The number of elementary particles in the
universe has been estimated to be $10^80$.  The world population is a
bit under 8 billion. Assuming everyone posts a Trumpian 10 tweets a day
and uses all of their 280 character allotment, that comes to $8\times
10^9 \times 10 \times 280 = 2.24\times 10^44$. The universe is 14 billion years.
That means...

People seem to be surprised probabilities are modeled using sets.
Sets have no structure, they are just a bag of things (_elements_). 
People also seem to be rather cavalier about specifying sample spaces.
-->
<p>The first step in any probability model is to specify the possible outcomes. The second step is to assign probabilities to the outcomes.</p>
<!--
[^monte-hall]
Monte Hall problem
It must be modeled as a Markov Decision Process.
-->
<h3 id="measure">Measure</h3>
<p>A <em>measure</em> <span class="math inline">\mu</span> on a set <span class="math inline">S</span> assigns numbers to subsets of <span class="math inline">S</span> and satisfies <span class="math display">
\mu(E\cup F) = \mu(E) + \mu(F) - \mu(E\cap F)
</span> for any subsets <span class="math inline">E,F\subseteq S</span> and <span class="math inline">\mu(\emptyset) = 0</span>. Measures do not count twice.</p>
<strong>Exercise</strong>. <em>Show if <span class="math inline">\nu(E\cup F) = \nu(E) + \nu(F) - \nu(E\cap F)</span> for <span class="math inline">E,F\subseteq S</span> then <span class="math inline">\mu = \nu - \nu(\emptyset)</span> is measure</em>.
<details>
<p><summary>Solution</summary></p>
<blockquote>
<p>By <span class="math inline">\mu = \nu - \nu(\emptyset)</span> we mean <span class="math inline">\mu(E) = \nu(E) - \nu(\emptyset)</span> for any subset <span class="math inline">E\subseteq S</span>. Clearly <span class="math inline">\mu(E\cup F) = \mu(E) + \mu(F) - \mu(E\cap F)</span> for any <span class="math inline">E,F\subseteq S</span>. Since <span class="math inline">\mu(\emptyset) = \nu(\emptyset) - \nu(\emptyset) = 0</span>, <span class="math inline">\mu</span> is a measure.</p>
</blockquote>
</details>
<strong>Exercise</strong>. <em>Show if <span class="math inline">\mu</span> is a measure then <span class="math inline">\mu(E\cup F) = \mu(E) + \mu(F)</span> for any subsets <span class="math inline">E</span> and <span class="math inline">F</span> with empty intersection <span class="math inline">E\cap F = \emptyset</span></em>.
<details>
<p><summary>Solution</summary></p>
<blockquote>
<p>Since <span class="math inline">\mu(\emptyset) = 0</span>, <span class="math inline">\mu(E\cup F) = \mu(E) + \mu(F) - \mu(E\cap F) = \mu(E) + \mu(F) - \mu(\emptyset) = \mu(E) + \mu(F)</span>.</p>
</blockquote>
</details>
<strong>Exercise</strong>. <em>Show if <span class="math inline">\mu</span> is a measure then <span class="math inline">\mu(E) = \mu(E\cap F) + \mu(E\cap F&#39;)</span> for any subsets <span class="math inline">E</span> and <span class="math inline">F</span> where <span class="math inline">F&#39; = S\setminus F = \{x\in S:x\not\in F\}</span> is the <em>complement</em> of <span class="math inline">F</span> in <span class="math inline">S</span></em>.
<details>
<p><summary>Solution</summary></p>
<blockquote>
<p>Note <span class="math inline">(E\cap F)\cup(E\cap F&#39;) = E\cap(F\cup F&#39;) = E\cap S = E</span> and <span class="math inline">(E\cap F)\cap(E\cap F&#39;) = E\cap(F\cap F&#39;) = E\cap\emptyset = \emptyset</span> so <span class="math inline">\mu(E\cap F) + \mu(E\cap F&#39;) = \mu((E\cap F)\cup(E\cap F&#39;) = \mu(E)</span>.</p>
</blockquote>
</details>
<h3 id="partition">Partition</h3>
<p>A <em>partition</em> splits a sample space into disjoint subsets with union equal to the sample space. Partitions are how <em>partial information</em> is represented. The events in the partition are called <em>atoms</em>. The way they represent partial information is you only know what atom an outcome belongs to, not the actual outcome.</p>
<p>Partitions define an <em>equivalence relation</em> on outcomes. We say <span class="math inline">\omega\sim\omega&#39;</span> if and only if they belong to the same atom.</p>
<p><strong>Exercise</strong>. <em>Show <span class="math inline">\omega\sim\omega</span>, <span class="math inline">\omega\sim\omega&#39;</span> implies <span class="math inline">\omega&#39;\sim\omega</span>, and <span class="math inline">\omega\sim\omega&#39;</span>, <span class="math inline">\omega&#39;\sim\omega&#39;&#39;</span> implies <span class="math inline">\omega\sim\omega&#39;&#39;</span></em>.</p>
<p>This is the definition of an equivalence relation. It is the mathematical way of saying two things are the “same” even if they are not equal.</p>
<h2 id="probability-measure">Probability Measure</h2>
<p>A <em>probability measure</em> <span class="math inline">P</span> on the sample space <span class="math inline">\Omega</span> is a measure taking values in the interval <span class="math inline">[0,1]</span> with <span class="math inline">P(\Omega) = 1</span>. The <em>probability</em> <span class="math inline">P(E)</span> for <span class="math inline">E\subseteq\Omega</span> represents a <em>degree of belief</em> that a random outcome will belong to the event <span class="math inline">E</span>. This is a somewhat nebulous and controversial notion. How do “random outcomes” occur?</p>
<p>Probability theory originated with games of chance. One way to interpret this is “How much money would you wager on an outcome involving rolling dice or selecting cards from a deck?”</p>
<p><strong>Exercise</strong>. <em>Show <span class="math inline">P(E\cup F) \le P(E) + P(F)</span> for any events <span class="math inline">E</span> and <span class="math inline">F</span> when <span class="math inline">P</span> is a probability measure</em>.</p>
<p><strong>Exercise</strong>. <em>Show <span class="math inline">P(\cup_i E_i) \le \sum_i P(E_i)</span> for any events <span class="math inline">(E_i)</span> when <span class="math inline">P</span> is a probability measure</em>.</p>
<p>If <span class="math inline">\Omega</span> has a finite number of outcomes, we can define a probability measure by specifying <span class="math inline">p_\omega = P(\{\omega\})</span> for <span class="math inline">\omega\in\Omega</span>. Note <span class="math inline">p_\omega\ge 0</span> and <span class="math inline">\sum_{\omega\in\Omega} = 1</span>. The probability of the event <span class="math inline">E\subseteq\Omega</span> is <span class="math inline">P(E) = \sum_{\omega\in E} p_\omega</span>.</p>
<p>For the two coin flip model (assuming the coin is fair) we assign probability of <span class="math inline">1/4</span> to each outcome. The probability of the first flip being heads is <span class="math inline">P(\{HH,HT\}) = P(\{HH\} \cup \{HT\}) = P(\{HH\} + P(\{HT\}) = 1/4 + 1/4 = 1/2</span>.</p>
<h2 id="random-variable">Random Variable</h2>
<p>A <em>random variable</em> is a symbol that can be used in place of a number when manipulating equations and inequalities with with additional information about the probability of the values it can take on.</p>
<p>The mathematical definition of a random variable is a function <span class="math inline">X\colon\Omega\to\mathbf{R}</span>. Its <em>cumulative distribution function</em> is <span class="math inline">F(x) = P(X\le x) = P(\{\omega\in\Omega\mid X(\omega) \le x\})</span>. More generally, given a subset <span class="math inline">A\subseteq\mathbf{R}</span> the probability that <span class="math inline">X</span> takes a value in <span class="math inline">X</span> is <span class="math inline">P(X\in A) = P(\{\omega\in\Omega\}: X(\omega\in A))\}</span>.</p>
<p>Two random variables have the same <em>law</em> if they have the same cdf.</p>
<p>The cdf tells you everything there is to know about the probability of the values the random variable can take on. For example, <span class="math inline">P(a &lt; X \le b) = F(b) - F(a)</span>.</p>
<p><strong>Exercise</strong>. <em>Show <span class="math inline">P(a\le X\le b) = \lim_{x\uparrow a} F(b) - F(x)</span></em>.</p>
<p><em>Hint</em>: <span class="math inline">[a,b] = \cap_n (a - 1/n, b]</span>.</p>
<p>In general <span class="math inline">P(X\in A) = \int_A dF(x)</span> for sufficiently nice subsets <span class="math inline">A\subset\mathbf{R}</span> where we are using <a href="https://mathworld.wolfram.com/StieltjesIntegral.html">Riemann–Stieltjes</a> integration.</p>
<p><strong>Exercise</strong>: <em>Show for any cumulative distribution function <span class="math inline">F</span> that <span class="math inline">F(x) \le F(y)</span> if <span class="math inline">x &lt; y</span>, <span class="math inline">\lim_{x\to -\infty} F(x) = 0</span>, <span class="math inline">\lim_{x\to\infty} F(x) = 1</span>, and <span class="math inline">F</span> is right continuous with left limits</em>.</p>
<p><em>Hint</em>: For right continuity use <span class="math inline">(-\infty, x] = \cap_n (-\infty, x + 1/n]</span>.</p>
<p>The cdf <span class="math inline">F(x) = \max\{0,\min\{1,x\}\}</span> defines the uniformly distributed random variable, <span class="math inline">U</span>, on the interval <span class="math inline">[0,1]</span>. For <span class="math inline">0\le a &lt; b\le 1</span>, <span class="math inline">P(a &lt; U \le b) = P(U\in (a,b]) = b - a</span> and <span class="math inline">P(U &lt; 0) = 0 = P(U &gt; 1)</span>.</p>
<p><strong>Exercise</strong>. <em>If <span class="math inline">X</span> has cdf <span class="math inline">F</span>, then <span class="math inline">X</span> and <span class="math inline">F^{-1}(U)</span> have the same law</em>.</p>
<p><strong>Exercise</strong>. <em>If <span class="math inline">X</span> has cdf <span class="math inline">F</span>, then <span class="math inline">F(X)</span> and <span class="math inline">U</span> have the same law</em>.</p>
<p>This shows a uniformly distributed random variable has sufficient randomness to generate any random variable. There are no random, random variables.</p>
<p>Given a cdf <span class="math inline">F</span> we can define a random variable having that distribution using the identity function <span class="math inline">X\colon\mathbf{R}\to\mathbf{R}</span>, where <span class="math inline">X(x) = x</span>. Let <span class="math inline">P</span> be the probability measure on <span class="math inline">\mathbf{R}</span> defined by <span class="math inline">P(A) = \int_A dF(x)</span>.</p>
<p>The mathematical definition is more flexible than defining a random variable by its cumulative distribution function.</p>
<h3 id="continuous-random-variable">Continuous Random Variable</h3>
<p>If <span class="math inline">F(x) = \int_{-\infty}^x F&#39;(u)\,du</span> we say the random variable is <em>continuously distributed</em>. The <em>density function</em> is <span class="math inline">f = F&#39;</span>. Any function satisfying <span class="math inline">f\ge 0</span> and <span class="math inline">\int_\mathbf{R} f(x)\,dx = 1</span> is a density function for a random variable.</p>
<h3 id="discrete-random-variable">Discrete Random Variable</h3>
<p>If <span class="math inline">dF = \sum_{\omega\in\Omega} p_\omega \delta_\omega</span> where <span class="math inline">\Omega\subseteq\mathbf{R}</span> is countable we say the random variable is <em>discretely distributed</em>. Here <span class="math inline">\delta_\omega</span> is the <em>delta function</em> with unit mass at <span class="math inline">\omega</span> defined by <span class="math inline">\int_{\mathbf{R}} f(x) \delta_\omega\,dx = f(\omega)</span> when <span class="math inline">f</span> is continuous at <span class="math inline">\omega</span>.</p>
<p><strong>Exercise</strong>. <em>Show if <span class="math inline">H_\omega(x) = 0</span> for <span class="math inline">\omega &lt; x</span> and <span class="math inline">H_\omega(x) = 1</span> for <span class="math inline">\omega\ge x</span> then <span class="math inline">f(\omega) = \int_{\mathbf{R}} f(x)\,dH_\omega(x)</span> when <span class="math inline">f</span> is continuous</em>.</p>
<p>Using this more precise notation, <span class="math inline">F = \sum_{\omega\in\Omega} p_\omega H_\omega</span>.</p>
<!--

## Examples

See ...

### Uniform

A random variable is uniformly distributed on the interval $[a, b]$ has density function
$f(x) = (x - a)/(b - a)$ if $a \le x \le b$ and $f(x) = 0$ if $x < a$ or $x > b$.

__Exercise__. _Show if $U$ is uniformly distributed on $[0,1]$ then $a(1 - U) + bU$
is uniformly distributed on $[a, b]$_.

### Cantor

Let's define a function on the interval $[0,1]$ as follows.
Every $x\in[0,1]$ can be written $x = \sum_{j>0} x_j/3^j$ where $x_j\in\{0,1,2\}$
The digits $(x_j)$ are the base 3 representaton of $x$. Define $F(x) = ???$

We have $F(0) = 0$, $F(1) = 1$, and $F$ is continuous...

The measure of the set where $F' = 0$ is 1.

### Measurable

A function $X\colon\Omega\to\mathbf{R}$ is _measurable_ with respect to the algebra $\mathcal{A}$
if $\{\omega\in\Omega : X(\omega) \le a\}$ belongs to $\mathcal{A}$ for all $a\in\mathbf{R}$.

__Exercise__. _Show $X$ is measurable if and only if it is constant on atoms of $\mathcal{A}$
when the algebra has a finite number of elements._

In this case we can write $X\colon\mathcal{A}\to\mathbf{R}$ as a function on the
atoms of $\mathcal{A}$.

### Expected Value

The _expected value_ of a random variable is defined by
$E[X] = \int_{-\infty}^\infty x\,dF(x)$. The expected value of any function of
a random variable is $E[f(X)] = \int_{-\infty}^\infty f(x)\,dF(x)$.

If $X\colon\mathcal{A}\to\mathbf{R}$ we can define expected value by ...
If $X = \sum a_i 1_{A_i}$ where $a_i\in\mathbf{R}$ and $A_i$ are events,
the _expected value_ of $X$ is $EX = \sum_i a_i P(A_i)$.

__Exercise__. Show that if $\sum_i a_i 1_{A_i} = 0$ then $\sum_i a_i P(A_i) = 0$.

_Hint_: Replace the $A_i$ by disjoint $B_j$ with $\sum_i a_i 1_{A_i} = \sum_j b_j 1_{B_j}$
so $b_j = 0$ for all $j$.

This shows expected value is [well-defined](https://en.wikipedia.org/wiki/Well-defined).

__Exercise__. Show $P(\cup_i A_i) = \sum_i P(A_i) - \sum_{i < j} P(A_i\cap A_j)
+ \sum_{i < j < k} P(A_i\cap A_j\cap A_k) \cdots$.

Hint: Use $(1_A - 1_{A_1})\cdots (1_A - 1_{A_n}) = 0$, where $A = \cup_{k=1}^n A_k$.

For any $p > 0$ $E[|Y|^p] = \int_\Omega |Y|^p\,dP
\ge \int_{\{|Y| > \lambda\}} |Y|^p\,dP
\ge \int_{\{|Y| > \lambda\}} \lambda^p\,dP
= \lambda^p P(|Y| > \lambda)$.
Taking $Y = X - E[X]$ and $p = 2$ yields
$P(|X - E[X]| > \lambda) \le \mathrm{Var}(X)/\lambda^2$.

## Joint Distribution

Two random variables, $X$ and $Y$, are defined by their _joint
distribution_, $H(x,y) = P(X\le x, Y\le y)$.  For example, the point $(X,Y)$ is
in the square $(a,b]\times (c,d]$ with probability
$P(a < X \le b, c < Y \le d) = P(X \le b, Y \le d) - P(X \le a) - P(Y \le c) + P(X \le a, Y \le c)$.

The _marginal distbutions_ are $F(x) = H(x,\infty)$ and $G(y) =  H(\infty,y)$,
where $F$ and $G$ are the cumulative distributions of $X$ and $Y$ respectively.

In general, the joint distribution of $X_1$, \ldots, $X_n$ is
$F(x_1,\ldots,x_n) = P(X_1\le x_1,\ldots, X_n\le x_n$).




### Moments

The _moments_ of a random variable, $X$, are $m_n = E[X^n]$, $n = 0,1,2,\ldots$.
They don't necessarily exist for all $n$, except for $n = 0$.
They also cannot be an arbitrary sequence of values.

Suppose all moments of $X$ exist, then for any complex numbers,
$(c_i)$, $0 \le E|\sum_i c_i X^i|^2 = E\sum_{j,k} c_j\bar{c_k} X^{j+k}
= \sum_{j,k} c_j \bar{c_k} m_{j+k}$.  This says the Hankel matrix, $M =
[m_{j+k}]_{j,k}$, is positive definite.  The converse is also true: if
the Hankel matrix is positive definite there exists a random variable
with the corresponding moments.  This is not a trivial result and the
random variable might not be unique.

% Dunford Schwartz Volume 2 pg 1251.
% Extending unbounded symmetric operators. Deficiency index.
 
### Cumulant

The _cumulant_ of a random variable, $X$, is $\kappa(s) = \kappa^X(s) = \log E\exp(sX)$.
The _cumulants_, $(\kappa_n)$, are the coefficients of the power series expansion
$\kappa(s) = \sum_{n>0}\kappa_n s^n/n!$.

It is easy to see $\kappa_1 = E[X]$ and $\kappa_2 = \mathrm{Var}(X)$. The third and fourth cumulants
are related to skew and kurtosis. We will see the exact relationship below.

If $c$ is a constant then $\kappa^{cX}(s) = \kappa^X(cs)$ so
$\kappa^{cX}_n = c^n\kappa^X_n$.  If $X$ and $Y$ satisfy $Ee^{sX}e^{sY}
= Ee^{sX}E^{sY}$ then $\kappa^{X + Y}(s) = \kappa^X(s) + \kappa^Y(s)$
and $\kappa^{X + Y}_n = \kappa^X_n + \kappa^Y_n$$

#### Bell Polynomial

The relationship between moments and cumulants is given by _Bell
polynomials_.  They are defined by $\exp(\sum_{n=1}^\infty a_n s^n/n!) =
\sum_0^\infty B_n(a_1,\ldots,a_n) s^n/n!$.  Taking the derivative
with respect to $s$ and equating powers of $s$ shows $B_0 =
1$ and $B_{n+1}(a_1,\ldots,a_{n+1} = \sum_{k=0}^n \binom{n}{k}
B_{n-k}(a_1,\ldots,a_{n-k}) a_{k+1}$.

Bell polynomials connect moments and cumulants of a random variable.
Since $E \exp(sX) = \sum_0^\infty E X^n s^n/n! =
\sum_0^\infty m_n s^n/n!$ where $m_n$ is the $n$-th moment and $E \exp(sX)
= \exp(\kappa(s)) = \exp(\sum_{n=1}^\infty \kappa_n s^n/n!)$.

__Exercise__: Show $m_n = \sum_{k=1}^n B_k(\kappa_1,\ldots,\kappa_n)$.

__Exercise__: Find the first five Bell polynomials.

In particular $m_1 = \kappa_1$ and $m_2 = \kappa_1^2 + \kappa_2$ so
$\kappa_1$ is the mean and $\kappa_2$ is the variance. If the mean is 0 and
the variance is 1, then $\kappa_3$ is the skew and $\kappa_4$ is the
[excess kurtosis](https://en.wikipedia.org/wiki/Kurtosis#Excess_kurtosis).


%Exercise. (Inclusion-Exclusion principal) Let $S$ be a finite set and
%let $f$ be any function defined on subsets of $S$.
%Define $\phi f(T) = \sum_{U\supseteq T} f(U)$ and
%$\psi g(T) = \sum_{U\supseteq T} (-1)^{|U| - |T|} g(T)$.
%These are both operators from $2^S\to\mathbf{R}$.
%Show $\phi\psi g = g$ and $\psi\phi f = f$.

%Hint: Group the sum by $|Y| - |T|$.

## Conditional Expectation

The _conditional expectation_ of an event $B$ given an event $A$ is
$P(B|A) = P(B\cap A)/P(A)$. In some sense, this reduces the sample space to $A$
since $P(A|A) = 1$ and $P(B\cup C|A) = P(B|A) + P(C|A) - P(B\cap C|A)$.
We also have $P(A|B) = P(A\cap B)/P(B)$ so $P(A|B) = P(B|A)P(A)/P(B)$. 
This is the simplest form of Bayes Theorem. It shows how to update your degree
of belief based on new information. Every probability is conditional on information.

Define the conditional expectation of the random variable $X$ with respect
to the event $A$ by $E[X|A] = E[X 1_A]/P(A)$.  If $X = 1_B$ then
this coincides with the definition of conditional expectation above.

Define the conditional expectation of $X$ with respect to the algebra
$\mathcal{A}$, $E[X|\mathcal{A}]:\mathcal{A}\to\mathbf{R}$, by
$E[X|\mathcal{A}](A) = E[X|A]$ for $A$ an atom of $\mathcal{A}$.

## Joint Distribution

Two random variables, $X$ and $Y$, are defined by their _joint
distribution_, $H(x,y) = P(X\le x, Y\le y)$.  For example, the point $(X,Y)$ is
in the square $(a,b]\times (c,d]$ with probability
$P(a < X \le b, c < Y \le d) = P(X \le b, Y \le d) - P(X \le a) - P(Y \le c) + P(X \le a, Y \le c)$.

The _marginal distbutions_ are $F(x) = H(x,\infty)$ and $G(y) =  H(\infty,y)$,
where $F$ and $G$ are the cumulative distributions of $X$ and $Y$ respectively.

In general, the joint distribution of $X_1$, \ldots, $X_n$ is
$F(x_1,\ldots,x_n) = P(X_1\le x_1,\ldots, X_n\le x_n$).

## Independent

The random variables $X$ and $Y$ are _independent_ if $H(x,y) = F(x)G(y)$ for all $x$ and $y$.
This is equivalent to $P(X\in A,Y\in B) = P(X\in A)P(Y\in B)$ for any sets $A$ and $B$.

We also have that $Ef(X)g(Y) = Ef(X) Eg(Y)$ for any functions $f$ and $g$ whenever all expected
values exist.

__Exercise__: Prove this for the case $f = \sum_i a_i 1_{A_i}$ and $g = \sum_j b_j 1_{B_j}$.

In general, $X_1$, \ldots, $X_n$ are independent if
$F(x_1,\ldots,x_n) = F_1(x_1)\cdots F_n(x_n)$, where $F_j$ is the law of $X_j$.

## Copula

A _copula_ is the joint distribution of uniformly distributed random variables on the unit interval.
The copula of $X$ and $Y$ is the joint distribution of $F^{-1}(X)$ and $G^{-1}(Y)$ where
$F$ and $G$ are the cumulative distributions of $X$ and $Y$ respectively:
$C(u,v) = C^{X,Y}(u,v) = P(F^{-1}(X) \le u, G^{-1}(Y) \le v)$.

__Exercise__: Show $C(u,v) = H(F(u),G(v))$ where
and $H$ is the joint distribution of $X$ and $Y$ and $F$ and $G$ are the cumulative
distribution of $X$, and $Y$.

__Exercise__: Show $H(x,y) = C(F^{-1}(x), G^{-1}(y))$

This shows how to use the copula and marginal distributions to recover the joint distribution.

An equivalent definition is a copula is a probability measure on $[0,1]^2$ with uniform
marginals. 

__Exercise__: Prove this.

If $U$ and $V$ are independent, uniformly distributed random variables on the unit interval
then $C(u,v) = uv$.

If $V=U$ then their joint distribution is
$C(u,v) = P(U\le u, V\le v) = P(U\le u, U\le v) = P(U\le \min\{u, v\}) = \min\{u,v\} = M(u,v)$.

If $V=1-U$ then their joint distribution is $C(u,v) = P(U\le u, V\le v) = P(U\le u, 1-U\le v)
= P(1-v\le U\le u) = \max\{u - (1 -v), 0\} = \max\{u + v - 1, 0\} = W(u,v)$

__Exercise__: (Fr&#233;chet-Hoeffding) For every copula, $C$, $W \le C \le M$.

Hint: For the upper bound use $H(x,y) \le F(x)$ and $H(x,y) \le G(y)$.
For the lower bound note $0\le C(u_1,v_1) - C(u_1, v_2) - C(u_2, v_1) + C(u_2, v_2)$
for $u_1 \ge u_2$ and $v_1 \ge v_2$.

## Examples

### Discrete

A _discrete_ random variable, $X$, is defined by
$x_i\in\mathbf{R}$ and $p_i > 0$ with $\sum p_i = 1$.
The probability the random variable takes on value $x_i$ is P(X = x_i) = $p_i$.

If a discrete random variable takes on a finite number of values, $n$, then
if $p_i = 1/n$ for all $i$ the variable is called _discrete uniform_.

### Bernoulli

A _Bernoulli_ random variable is a discrete random variable with $P(X = 0) = p$, $P(X = 1) = 1 - p$.

### Binomial

A _Binomial_ random variable is a discrete random variable with
$P(X = k) = \binom{n}{k}p^k(1-p)^{n-k}$, $k = 0$, \ldots, $n$.

### Uniform

A _continuous uniform_ random variable on the interval $[a,b]$ has density
$f(x) = 1_{[a,b]}/(b - a)$.

A _discrete uniform_ random variable on $\Omega = \{x_1,\ldots,x_n\}$
has $P(X = x_j) = 1/n$ for $j = 1,\ldots,n$.

### Normal

The _standard normal_ random variable, $Z$, has density function $\phi(x) = \exp(-x^2/2)/\sqrt{2\pi}$.

If $X$ is normal then $E\exp(N) = \exp(E[N] + \mathrm{Var}(N)/2)$ so the cumulants satisfy
$\kappa_n = 0$ for $n > 2$.

This follows from 
$$
\begin{aligned}
E[e^N] &= E[e^{\mu + \sigma Z}] \\
       &= \int_{-\infty}^\infty e^{\mu + \sigma z} e^{-z^2/2}\,dz/\sqrt{2\pi}\\
       &= e^{\mu + \sigma^2/2} \int_{-\infty}^\infty e^{-(z - \sigma)^2/2}\,dz/\sqrt{2\pi}\\
       &= e^{\mu + \sigma^2/2} \int_{-\infty}^\infty e^{-z^2/2}\,dz/\sqrt{2\pi}\\
       &= e^{\mu + \sigma^2/2}
\end{aligned}
$$

For any normal random variable, $N$, $E[e^N f(N)] = E[e^N] E[f(N + \mathrm{Var}(N)]$.

__Exercise__. Prove this by first showing $E[e^{\sigma Z} f(Z)] = e^{\sigma^2/2} E[f(Z + \sigma)]$.

If $N$, $N_1$, \ldots, are jointly normal then
$E[e^N f(N_1,\ldots)] = E[e^N] E[f(N_1 + \Cov(N,N_1),\ldots)]$.

### Poisson

A _Poisson_ random variable with parameter $\lambda$ is defined by
$P(X = k) = e^{-\lambda}\lambda^k/k!$ for $k = 0, 1, \ldots$.

If $X$ is Poisson with parameter $\lambda$ then 
$$
\begin{aligned}
Ee^{sX} &= \sum_{k=0}^\infty e^{sk} e^{-\lambda}\lambda^k/k!\\
        &= \sum_{k=0}^\infty  (e^s\lambda)^ke^{-\lambda}/k!\\
        &= \exp(\lambda(e^s - 1))
\end{aligned}
$$
so $\kappa(s) = \lambda(e^s - 1)$ and $\kappa_n = \lambda$ for all $n$.

### Infinitely Divisible

A random variable, $X$, is _infinitely divisible_ if for any positive integer, $n$,
there exist independent, identically distributed random variables $X_1$,\ldots,$X_n$
such that $X_1 + \cdots + X_n$ has the same law as $X$.

A theorem of Kolmogorov states for every infinitely divisible random variable the exists
a number $\gamma$ and a non-decreasing function $G$ with

$$
\kappa(s) = \log E e^{sX} = \gamma s + \int_{-\infty}^\infty K_s(x)\,dG(x),
$$

where $K_s(x) = (e^{sx} - 1 - sx)/x^2 = \sum_{n=2}^\infty x^{n-2}s^n/n!$.
Note if $G(x) = 1_{(-\infty,0]}$ then $\kappa(s) = \gamma s + K_s(0) = \gamma s + s^2/2$
so the random variable is normal.

Note the cumulants of the random variable are $\kappa_1 = \gamma$ and
$\kappa_n = \int_{-\infty}^\infty x^{n - 2}\,dG(x)$ for $n \ge 2$.

If $G(x) = a^2 1_{(-\infty,a]}$ for $a\not=0$ then
$$
\begin{aligned}
\kappa(s) &= \gamma s + a^2 K_s(a)\\ 
          &= \gamma s + a^2 \sum_{n=2}^\infty a^{n-2}s^n/n!\\ 
          &= \gamma s + \sum_{n=2}^\infty a^n s^n/n!\\ 
          &= \gamma s - as + \sum_{n=1}^\infty a^n s^n/n!\\ 
          &= (\gamma - a)s + \sum_{n=1}^\infty a^n s^n/n!\\ 
\end{aligned}
$$

so the random variable is Poisson with parameter $a$ plus the constant $\gamma - a$.

This theorem states every infinitely divisible random variable can be
approximated by a normal plus a linear combination of independent Poisson
random variables.

If $X = \mu + \sigma Z + \sum_j \alpha_j a_j^2 P_j$ where $P_j$ is Poisson
with parameter $a_j$, then
$$
\kappa(s) = \mu s + \sigma s^2/2 + \sum_j \alpha_j (e^{a_j s} - 1) - \alpha_j s
$$


## Unsorted

### Characteristic Function

The _characteristic function_ of a random variable, $X$, is $\xi(t) = \kappa(it)$.

### Fourier Transform

The _Fourier transform_ is $\psi(t) = \xi(-t) = \kappa(-it)$.
Clearly $\psi(t) = \xi(-t)$.


## Remarks

Cheval de Mere

Pascal

Bernoulli(s)

Kolmogorov

Willy Feller

These can be used to prove the _central limit theorem_:
if $X_j$ are independent, identically distributed random variables with mean zero
and variance one, then $(X_1 + \cdots X_n)/sqrt{n}$ converges to a standard
normal random variable.

Probability and Logic (Ramsey)

Littlewood's law P(miracle) is large. 1 event per second, 1/10^6 are miracles, 8 hour days.

Birthday problem.

UUIDs

## Partition

A _partition_ of a set $\Omega$ is a collection of subsets (events)
that are _pairwise disjoint_ with union $\Omega$.
A partition $\mathcal{A} = \{A_i\}_{i\in I}$ satisfies $A_i\subseteq\Omega$ for all $i\in I$,
$A_i\cap A_j = \emptyset$ if $i \not= j$, and $\cup_{i\in I} A_i = \Omega$.
The elements $A_i$ of the partition $\mathcal{A}$ are called _atoms_.

__Exercise__. _If $\{A_i\}$ are pairwise disjoint show $A_i\cap A_j\cap
A_k = \emptyset$ if $i$, $j$, and $k$ are distinct._

__Exercise__. _If $\{A_i\}$ are pairwise disjoint show $A_i\cap A_j\cap
A_k = \emptyset$ if $i$, $j$, and $k$ are not all the same._

__Exercise__. _If $\{A_i\}$ are pairwise disjoint show $\cap_{j\in J}A_j =
\emptyset$ if $J\subseteq I$ has at least two elements._

Partitions represent partial information. 
Complete information means knowing what outcome $\omega\in\Omega$ occured.
This corresponds to the _finest_ partition consisting of singletons
$\{\{\omega\}:\omega\in\Omega\}$.  Complete lack of information
corresponds to the _coarsest_ partion consisting of one set $\{\Omega\}$.
Partial information correponds to knowing what atom of a partition $\omega$ belongs to.

Partitions have a _partial ordering_ where $\mathcal{A}\preceq\mathcal{B}$ indicates
every atom of $\mathcal{A}$ is a union of atoms in $\mathcal{B}$. In this case we say
$\mathcal{B}$ is a _refinement_ of $\mathcal{A}$ and $\mathcal{B}$ is _finer_ than $\mathcal{A}$
or $\mathcal{A}$ is _coarser_ than $\mathcal{B}$.

Recall a partial ordering is _reflexive_: $\mathcal{A}\preceq\mathcal{A}$ and
_transitive_:$\mathcal{A}\preceq\mathcal{B}$ and $\mathcal{B}\preceq\mathcal{C}$
imply $\mathcal{A}\preceq\mathcal{C}$ for $A,B,C\subseteq\Omega$.

__Exercise__. _Show refinement is a partial ordering._

### Algebra of Sets

More advanced texts use an _algebra_ of sets instead of a partition.
An algebra of sets is a collection of subsets closed under complement and union
that also contains the empty set.

Since algebras are closed under complement $\Omega = \emptyset' =
\Omega\setminus\emptyset$
is also in the algebra.

By [De Morgan's Laws](https://en.wikipedia.org/wiki/De_Morgan's_laws)
an algebra is also closed under intersection since
$A\cap B = (A'\cup B')'$.

If $E$ and $F$ are elements of an algebra we can use plain English to
talk about 'not $E$' ($E'= \Omega\setminus E$), '$E$ or $F$' ($E\cup F$), and
'$E$ and $F$' ($E\cap F$). The phrases '$E$ implies $F$' and 'if $E$ then $F$'
correspond to $E\subseteq F$.

An _atom_ of an algebra $\mathcal{A}$ is an element $A\in\mathcal{A}$ with
the property $B\subseteq A$ and $B\in\mathcal{A}$ imply $B = \emptyset$
or $B = A$.

__Exercise__. _If an algebra is finite its atoms form a partition._

_Hint_: Show $A_\omega = \cap\{B\in\mathcal{A}:\omega\in B\}$ is an atom for all $\omega\in\Omega$. 

If $\mathcal{A}$ is infinite then there is no guarantee the intersection above is still
in $\mathcal{A}$. A _countably addititve measure_ guarantees the algebra is closed under
countable unions (and hence countable intersections) and $P(\cup_i E_i) = \sum_i P(E_i)$ if
$(E_i)_{i\in\mathbf{N}}$ are pairwise disjoint. These conditions are required to prove
_limit theorems_ about measures.

For example, The Borel-Cantelli lemma states that if $\sum_i P(E_i) <
\infty$ for any countable collection of events $(E_i)_{i\in\mathbf{N}}$
then none of the events can occur _infinitely often_. The outcome $\omega$ occurs
after $k$ if $\omega\in\cup_{k > n} E_k$. If an outcome occurs a finite number
of times then $\omega\not\in\cup_{k > n} E_k$ for sufficiently large $k$.
If the outcome occurs in an infinite number of events then
$\omega\in\cap_n \cup_{k > n} E_k$ and we say $\omega$ occurs _infinitely often_.
For any $\epsilon > 0$ there exists $n$ such that $\sum_{k > n} P(E_k) < \epsilon$
since the infinite sum converges to a finite value. 

-->
<section class="footnotes" role="doc-endnotes">
<hr />
<ol>
<li id="fn1" role="doc-endnote"><p>The _cartesian product of sets <span class="math inline">A</span> and <span class="math inline">B</span> is the set of <em>pairs</em> <span class="math inline">A\times B = \{(a,b):a\in A, b\in B\}</span>. The number of elements in <span class="math inline">A\times B</span> is the number of elements in <span class="math inline">A</span> times the number of elements in <span class="math inline">B</span>.<a href="#fnref1" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
</ol>
</section>
<footer>
Return to <a href="index.html">index</a>.
</footer>
</body>
</html>
