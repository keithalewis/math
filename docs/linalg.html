<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="" xml:lang="">
<head>
  <meta charset="utf-8" />
  <meta name="generator" content="pandoc" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
  <meta name="author" content="Keith A. Lewis" />
  <title>Linear Algebra</title>
  <style>
    code{white-space: pre-wrap;}
    span.smallcaps{font-variant: small-caps;}
    span.underline{text-decoration: underline;}
    div.column{display: inline-block; vertical-align: top; width: 50%;}
    div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
    ul.task-list{list-style: none;}
  </style>
  <link rel="stylesheet" href="math.css" />
  <script src="https://cdn.jsdelivr.net/npm/katex@0.12.0/dist/katex.min.js"></script>
  <script>document.addEventListener("DOMContentLoaded", function () {
   var mathElements = document.getElementsByClassName("math");
   for (var i = 0; i < mathElements.length; i++) {
    var texText = mathElements[i].firstChild;
    if (mathElements[i].tagName == "SPAN") {
     katex.render(texText.data, mathElements[i], {
      displayMode: mathElements[i].classList.contains('display'),
      throwOnError: false,
      fleqn: true
     });
  }}});
  </script>
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.12.0/dist/katex.min.css" />
  <!--[if lt IE 9]>
    <script src="//cdnjs.cloudflare.com/ajax/libs/html5shiv/3.7.3/html5shiv-printshiv.min.js"></script>
  <![endif]-->
</head>
<body>
<header id="title-block-header">
<h1 class="title">Linear Algebra</h1>
<p class="author">Keith A. Lewis</p>
</header>
<p>This is not a beginners guide to linear algebra. It is a breviloquent collection of pertinent facts about vector spaces and the linear transformations between them. Although it is complete and self-contained you should already be familiar with basic linear algebra before reading this. Statements and proofs are concise, so read them twice. Do the exercises to confirm your understanding.</p>
<p>I make no apologies for the shamelessly mathematical exposition and hope it engenders an appeciation for the thrill of literally ‘doing the math’ to unequivocally establish absolute truth.</p>
<h2 id="introduction">Introduction</h2>
<p>Vector spaces occupy a sweet spot in the menagerie of mathematical structures. They are completely classified up to <em>isomorphism</em> by their <em>dimension</em>. A <em>vector space</em> is an <em>abelian group</em> with a <em>scalar multiplication</em> that satisfies a <em>distributive law</em> with respect to the vector addition. A vector is not just a list of numbers, it is a mathematical object that satisfies these axioms. For example, <em>functions</em> are vectors and <em>linear transformations</em> between vector spaces are also vectors.</p>
<p>A linear transformation is a function between vector spaces that preserves the vector space structure. They are completely classified up to <em>similarity</em> for finite dimensional vector spaces by their <em>eigenvalues</em> and the <em>multiplicity</em> of each eigenvalue</p>
<!--
Linear transformations from a finite dimensional vector space to
itself are categorized up to _similariy_ by a list of _eigenvalues_
together with their _multiplicities_. Each eigenvalue and multiplicity
is associated with an _invariant subspace_ having dimension equal to
the multiplicity.  If the multiplicity is 1 then $Tv = \lambda v$ where
$v$ is an eigenvector corresponding to the eigenvalue $\lambda$.  We can
write this as $(T - \lambda I)v = 0$ where $I$ is the _identity operator_.
The associated invariant subspace is spanned by $v$.  If the multiplicity
is $m$ then $(T - \lambda I)^m v = 0$ for the generalized eigenvector $v$
and $(T - \lambda I)^k v\not= 0$ for $k < m$.  The associated invariant
subspace is spanned by $v$, $Tv$, \ldots, $T^{m-1}v$.

This probably makes no sense to you at this point, but it describes the
Jordan canonical form of a linear transformation. After you master the
following material these statements will become completely obvious.
-->
<h2 id="vector-space">Vector Space</h2>
<p>The ingredients of a <em>vector space</em> are a set <span class="math inline">V</span> of vectors and a binary addition that satisfies the abelian group axioms:</p>
<dl>
<dt><em>Associative</em></dt>
<dd><span class="math inline">x + (y + z) = (x + y) + z</span> for <span class="math inline">x,y,z\in V</span>.
</dd>
<dt><em>Commutative</em></dt>
<dd><span class="math inline">x + y = y + x</span> for <span class="math inline">x,y\in V</span>.
</dd>
<dt><em>Identity</em></dt>
<dd>There is a <span class="math inline">0\in V</span> with <span class="math inline">x + 0 = x</span> for <span class="math inline">x\in V</span>.
</dd>
<dt><em>Inverse</em></dt>
<dd>Every vector has an additive inverse <span class="math inline">-x</span> with <span class="math inline">x + (-x) = 0</span>.
</dd>
</dl>
<p>A vector space also specifies a <em>field</em> of <em>scalars</em> <span class="math inline">\bm{F}</span> (usually the real <span class="math inline">\bm{R}</span> or complex <span class="math inline">\bm{C}</span> numbers) and a scalar multiplication that satisfies</p>
<dl>
<dt><em>Distributive</em></dt>
<dd><span class="math inline">\alpha (x + y) = \alpha x + \alpha y</span>, for <span class="math inline">\alpha\in\bm{F}</span> and <span class="math inline">x,y\in V</span>.
</dd>
</dl>
<p><strong>Lemma</strong>. <em>For any vector <span class="math inline">x</span>, <span class="math inline">x + x = x</span> implies <span class="math inline">x = 0</span></em>. <span class="math display">
\begin{aligned}
    x + x &amp;= x &amp; &amp; \\
    (x + x) + (-x) &amp;= x + (-x) &amp;\mathrm{substitution} \\
    x + (x + (-x)) &amp;= x + (-x) &amp;\mathrm{associative} \\
    x + 0 &amp;= 0 &amp;\mathrm{inverse} \\
    x &amp;= 0 &amp;\mathrm{identity} \\
\end{aligned}
</span></p>
<p>By <em>substitution</em> we mean that if <span class="math inline">P(x)</span> is a logical statement containing the symbol <span class="math inline">x</span> we can replace each occurence of <span class="math inline">x</span> by any other symbol <span class="math inline">y</span>, <span class="math inline">x\mapsto y</span>, as long as <span class="math inline">y</span> does not occur in <span class="math inline">P(x)</span>. Using the true statement <span class="math inline">a = b \Rightarrow a + c = b + c</span> we make the substitutions <span class="math inline">a \mapsto x + x</span>, <span class="math inline">b \mapsto x</span>, and <span class="math inline">c \mapsto (-x)</span> then use modus ponens.</p>
<p><strong>Exercise</strong>. <em>Show the additive identity is unique</em>.</p>
<p><em>Hint</em>. If <span class="math inline">0&#39;</span> is another identity then <span class="math inline">0 = 0 + 0&#39;</span>. Your proof can be used for any group, abelian or not.</p>
<p><strong>Exercise</strong>. <em>Show for <span class="math inline">x\in V</span> that <span class="math inline">(-1)x = -x</span></em>.</p>
<p><em>Hint</em>. The left hand side is the scalar multiplication of <span class="math inline">-1\in\bm{F}</span> by <span class="math inline">x</span>. The right hand side is the additive inverse of <span class="math inline">x</span>. You need to show <span class="math inline">x + (-1)x = 0</span>. Use the distributed law.</p>
<p><strong>Exercise</strong>. <em>Show for <span class="math inline">x\in V</span> that <span class="math inline">-(-x) = x</span></em>.</p>
<p>If <span class="math inline">\bm{F}^X = \{f\colon X\to \bm{F}\}</span> is the set of all functions from <span class="math inline">X</span> to <span class="math inline">\bm{F}</span> we can define <span class="math inline">(f + g)(x) = f(x) + g(x)</span> and <span class="math inline">(\alpha f)(x) = \alpha f(x)</span> for <span class="math inline">f,g\in\bm{F}^X</span> and <span class="math inline">\alpha\in\bm{F}</span>. It is customary to write <span class="math inline">c(X)</span> for this space.</p>
<p><strong>Exercise</strong>. <em>Show <span class="math inline">c(X)</span> is a vector space</em>.</p>
<p>The functions in <span class="math inline">c(X)</span> that are zero except at a finite number of elements of <span class="math inline">X</span> is customarily written <span class="math inline">c_{00}(X)</span>. If <span class="math inline">X</span> is finite then <span class="math inline">\bm{F}^X = c_{00}(X)</span>. If <span class="math inline">X</span> has <span class="math inline">n</span> elements it is customary to write <span class="math inline">\bm{F}^n = \{(x_1,\ldots,x_n):x_j\in\bm{F}, 1\le j\le n\}</span>.</p>
<p><strong>Exercise</strong>. <em>Show <span class="math inline">c_{00}(X)</span> is a vector space</em>.</p>
<p>If <span class="math inline">X = \bm{N}</span> is the set of <em>natural numbers</em> define <span class="math inline">c_0(\bm{N}) = c_0</span> to be the functions <span class="math inline">v\in c(\bm{N})</span> such that <span class="math inline">\lim_{n\to\infty} v(n) = 0</span>.</p>
<p><strong>Exercise</strong>. <em>Show <span class="math inline">c_0</span> is a vector space</em>.</p>
<p>The vector space <span class="math inline">c_{00}(X)</span> has an <em>inner product</em> defined by <span class="math inline">v\cdot w = \sum_{x\in X} v(x) w(x) = \sum_{x\in X} v_x w_x</span> for <span class="math inline">v,w\in c_{00}(X)</span>. Since multiplication in <span class="math inline">\bm{F}</span> is commutative <span class="math inline">v\cdot w = w\cdot v</span>.</p>
<p><strong>Exercise</strong>. <em>Show <span class="math inline">(\alpha u + \beta v)\cdot w = \alpha(u\cdot w) + \beta(v\cdot w)</span> for <span class="math inline">\alpha, \beta\in\bm{F}</span> and <span class="math inline">u,v,w\in c_{00}(X)</span></em>.</p>
<p><strong>Exercise</strong>. <em>Show <span class="math inline">v\cdot v = 0</span> implies <span class="math inline">v = 0</span> for <span class="math inline">v\in c_{00}(X)</span></em>.</p>
<p>Define the <em>Kronecker delta function</em> <span class="math inline">\delta_x\in c_{00}(X)</span> by <span class="math inline">\delta_x(y) = 1</span> if <span class="math inline">y = x</span> and <span class="math inline">\delta_x(y) = 0</span> if <span class="math inline">y \not= x</span>.</p>
<p><strong>Exercise</strong>. <em>Show <span class="math inline">v = \sum_{x\in X} (v\cdot\delta_x) \delta_x</span> for <span class="math inline">v\in c_{00}(X)</span></em>.</p>
<h2 id="linear-transformation">Linear Transformation</h2>
<p>When studying mathematical objects it is useful to study functions between them that preserve the structure of the objects.</p>
<p>If <span class="math inline">V</span> and <span class="math inline">W</span> are vector spaces over the same field <span class="math inline">\bm{F}</span> then a function <span class="math inline">T\colon V\to W</span> is a <em>linear transformation</em> if <span class="math inline">T(\alpha x + y) = \alpha Tx + T y</span> for <span class="math inline">\alpha \in\bm{F}</span> and <span class="math inline">x,y\in V</span>. Note the addition and scalar multiplicate on the left-hand side of the equality are those of <span class="math inline">V</span> and on the right-hand side are those of <span class="math inline">W</span>. Linear transformations are functions that preserve the vector space structure.</p>
<p><strong>Exercise</strong>. <em>Show <span class="math inline">T(\alpha x + \beta y) = \alpha Tx + \beta T y</span> for <span class="math inline">\alpha,\beta \in\bm{F}</span> and <span class="math inline">x,y\in V</span></em>.</p>
<p>The set of all linear transformations from <span class="math inline">V</span> to <span class="math inline">W</span> is denoted <span class="math inline">\mathcal{L}(V,W)</span>. The sum of <span class="math inline">T,S\in \mathcal{L}(V,W)</span> is defined by <span class="math inline">(T + S)v = Tv + Sv</span> for <span class="math inline">v\in V</span>. If <span class="math inline">\alpha\in\bm{F}</span> define <span class="math inline">\alpha T</span> by <span class="math inline">(\alpha T)v = \alpha(T v)</span> for <span class="math inline">v\in V</span>.</p>
<p><strong>Exercise</strong>. <em>Show <span class="math inline">\mathcal{L}(V,W)</span> is a vector space</em>.</p>
<p>If <span class="math inline">T\in\mathcal{L}(c_{00}(X), c_{00}(Y))</span> then <span class="math inline">T\delta_x = \sum_{y\in Y} t_{xy} \delta_y</span> for some <span class="math inline">t_{xy}\in\bm{F}</span> where <span class="math inline">\{y\in Y:t_{xy}\not=0\}</span> is finite. If <span class="math inline">S\in\mathcal{L}(c_{00}(Y), c_{00}(Z))</span> then <span class="math inline">S\delta_y = \sum_{z\in Z} s_{yz} \delta_z</span> for some <span class="math inline">s_{yz}\in\bm{F}</span> where <span class="math inline">\{z\in Z:s_{yz}\not=0\}</span> is finite.</p>
<p><strong>Exercise</strong>. <em>Show <span class="math inline">(ST)\delta_x = \sum_{z\in Z}(\sum_{y\in Y} t_{xy} s_{yz})\delta_z</span></em>.</p>
<p>The <em>kernel</em> of a linear transformation <span class="math inline">T\colon V\to W</span> is <span class="math inline">\ker T = \{v\in V:Tv = 0\}</span>.</p>
<p><strong>Exercise</strong>. <em>Show the kernel of a linear transformation is a vector space</em>.</p>
<p>A linear transformation is <em>injective</em> if <span class="math inline">Tx = Ty</span> implies <span class="math inline">x = y</span>.</p>
<p><strong>Exercise</strong>. <em>Show a linear transformation is injective if and only if its kernel is <span class="math inline">\{0\}</span></em>.</p>
<p>The <em>range</em> of a linear transformation <span class="math inline">T\colon V\to W</span> is <span class="math inline">\operatorname{ran}T = \{Tv\in W:v\in V\}</span>. If <span class="math inline">\operatorname{ran}T = W</span> we say <span class="math inline">T</span> is <em>surjective</em>.</p>
<p><strong>Exercise</strong>. <em>Show the range of a linear transformation is a vector space</em>.</p>
<p>An linear transformation that is <em>bijective</em> (injective and surjective) is an <em>isomorphism</em> from <span class="math inline">V</span> to <span class="math inline">W</span>. We write <span class="math inline">V\cong W</span> if such an operator exists and say <span class="math inline">V</span> is isomorphic to <span class="math inline">W</span>.</p>
<p><strong>Exercise</strong>. <em>Show <span class="math inline">\cong</span> is an equivalence relation on vector spaces</em>.</p>
<p>This means <span class="math inline">V\cong V</span>, <span class="math inline">V\cong W</span> implies <span class="math inline">W\cong V</span>, and <span class="math inline">U\cong V</span> and <span class="math inline">V\cong W</span> implies <span class="math inline">U\cong W</span> for vector spaces <span class="math inline">U</span>, <span class="math inline">V</span>, and <span class="math inline">W</span>.</p>
<!--
If $T$ is an endomorphism on $V$ and $Tv = \lambda v$ for some $v\in V$ and
$\lambda\in\bm{F}$ then $v$ is an _eigenvector_ of $T$ with _eigenvalue_ $\lambda$.
These completely determine how $T$ acts on the one-dimensional subspace
$\bm{F}v = \{\alpha v:\alpha\in\bm{F}\}$.

__Exercise__. _Show $\bm{F}v$ is a subspace and $Tu = \lambda u$ for any $u\in\bm{F}v$_.
-->
<p>If <span class="math inline">W = V</span> we write <span class="math inline">\mathcal{L}(V)</span> for <span class="math inline">\mathcal{L}(V,V)</span> and call the tranformations <em>endomorphisms</em> of <span class="math inline">V</span>. If <span class="math inline">U\subseteq V</span> and <span class="math inline">T</span> is an endomorphism on <span class="math inline">V</span> then <span class="math inline">U</span> is <em>invariant</em> for <span class="math inline">T</span> if <span class="math inline">TU\subseteq U</span>.</p>
<p><strong>Exercise</strong>. <em>Show the kernal and range of an endomorphism are invariant</em>.</p>
<p>Two endomorphisms <span class="math inline">R,T</span> on <span class="math inline">V</span> are <em>similar</em> if there exists an isomorphism <span class="math inline">S</span> with <span class="math inline">R = S^{-1}TS</span>. We write <span class="math inline">R\simeq T</span> if so.</p>
<p><strong>Exercise</strong>. <em>Show similarity is an equivlence relation on endomorphisms</em>.</p>
<p>Hint: <span class="math inline">S_0^{-1}S_1 = (S_1^{-1}S_0)^{-1}</span> if <span class="math inline">S_0</span> and <span class="math inline">S_1</span> are isomorphisms.</p>
<h3 id="subspace">Subspace</h3>
<p>Just as factoring an integer into its prime factors can provide useful information about the integer, vector spaces can be usefully factored down into smaller <em>subspaces</em>.</p>
<p>A subset <span class="math inline">U</span> of a vector space <span class="math inline">V</span> is a subspace if <span class="math inline">U</span> is also a vector space.</p>
<p><strong>Exercise</strong>. <em>Show <span class="math inline">U\subseteq V</span> is a subspace if and only if <span class="math inline">U + U\subseteq U</span> and <span class="math inline">\bm{F} U\subseteq U</span></em>.</p>
<p>We use the notation <span class="math inline">U + U = \{x + y:x\in U, y\in U\}</span> and <span class="math inline">\bm{F} U = \{\alpha x:\alpha \in\bm{F}, x\in U\}</span>.</p>
<p><strong>Exercise</strong>. <em>If <span class="math inline">U</span> and <span class="math inline">W</span> are subspaces then <span class="math inline">U + W</span> and <span class="math inline">U\cap W</span> are also subspaces</em>.</p>
<p>If <span class="math inline">U\cap W = \{0\}</span> then <span class="math inline">U + W</span> is called an <em>interal sum</em>.</p>
<p><strong>Exercise</strong>. <em>Let <span class="math inline">U</span> and <span class="math inline">W</span> be subspaces of <span class="math inline">V</span> with <span class="math inline">U\cap W = \{0\}</span>. If <span class="math inline">u + w = u&#39; + w&#39;</span> with <span class="math inline">u,u&#39;\in U</span> and <span class="math inline">w,w&#39;\in W</span> show <span class="math inline">u = u&#39;</span> and <span class="math inline">w = w&#39;</span></em>.</p>
<p><em>Hint</em>. <span class="math inline">u - u&#39;\in U</span> and <span class="math inline">w&#39; - w\in W</span>.</p>
<p>This shows every vector <span class="math inline">v\in U + W</span> has a unique decomposition <span class="math inline">v = u + w</span> with <span class="math inline">u\in U</span> and <span class="math inline">w\in W</span> whenever <span class="math inline">U\cap W = \{0\}</span>.</p>
<h4 id="lattice-of-subspaces">Lattice of Subspaces</h4>
<p>Subspaces of a vector space form a <em>lattice</em> where <span class="math inline">+</span> is the <em>join</em> and <span class="math inline">\cap</span> is the <em>meet</em>. Since <span class="math inline">U + V = V</span> for all subspaces <span class="math inline">U</span>, <span class="math inline">V</span> is the identity element of the join. Since <span class="math inline">U \cap \{0\} = \{0\}</span> for all subspaces <span class="math inline">U</span>, <span class="math inline">\{0\}</span> is the identity element of the meet.</p>
<p><strong>Exercise</strong>. (Absorbtion laws) <em>If <span class="math inline">U</span> and <span class="math inline">W</span> are subspaces then <span class="math inline">U + (U \cap W) = U</span> and <span class="math inline">U\cap(U + W) = U</span></em>.</p>
<p>The lattice of subspaces is also <em>distributive</em>.</p>
<p><strong>Exercise</strong>. (Distributive laws) <em>If <span class="math inline">U</span>, <span class="math inline">V</span>, and <span class="math inline">W</span> are subspaces then <span class="math inline">U \cap (V + W) = (U \cap V) + (U \cap W)</span> and <span class="math inline">U + (V\cap W) = (U + V)\cap(U + W)</span></em>.</p>
<p>Either of these implies the other in any lattice. This was not noticed until some time after the the invention of lattice theory. [cite??]</p>
<p>Subspaces of <span class="math inline">V</span> form a <em>bounded lattice</em> with <em>top element</em> <span class="math inline">V</span> and <em>bottom element</em> <span class="math inline">\{0\}</span>.</p>
<p>The lattice structure of subspaces is used in Quantum Mechanics. [cite?]</p>
<h3 id="span">Span</h3>
<p>If <span class="math inline">x\in V</span> then <span class="math inline">\bm{F}\{x\} = \{\alpha x:\alpha \in\bm{F}\}</span> is the one-dimensional subspace <em>spanned</em> by <span class="math inline">x</span>.</p>
<p><strong>Exercise</strong>. <em>Show <span class="math inline">\bm{F}\{x\}</span> is the smallest subspace of <span class="math inline">V</span> containing <span class="math inline">x</span></em>.</p>
<p>More generally, let <span class="math inline">X</span> be any collection of vectors in <span class="math inline">V</span>. The <em>span</em> of the collection is the smallest subspace of <span class="math inline">V</span> containing <span class="math inline">X</span> and is denoted <span class="math inline">\operatorname{span}X</span> or <span class="math inline">\vee X</span>.</p>
<p>A <em>linear combination</em> of vectors is a finite sum <span class="math inline">\sum_j \alpha_j x_j</span> where <span class="math inline">\alpha_j\in\bm{F}</span> and <span class="math inline">x_j\in V</span>.</p>
<p><strong>Exercise</strong>. <em>Show the span of <span class="math inline">X</span> is the set of all linear combinations of vectors from <span class="math inline">X</span></em>.</p>
<p>Given a set <span class="math inline">X</span> define <span class="math inline">\delta_x\in c(X)</span> by <span class="math inline">\delta_x(y) = 1</span> if <span class="math inline">y = x</span> and <span class="math inline">\delta_x(y) = 0</span> if <span class="math inline">y \not= x</span>.</p>
<p><strong>Exercise</strong>. <em>Show the span of <span class="math inline">\{\delta_x:x\in X\}</span> is <span class="math inline">c_{00}(X)</span></em>.</p>
<h3 id="independent">Independent</h3>
<p>A key property of a collection of vectors is <em>independence</em>. A collection of vectors <span class="math inline">X</span> in the vector space <span class="math inline">V</span> are independent if every linear combination <span class="math inline">\sum_j \alpha_j x_j = 0</span> where <span class="math inline">\alpha_j\in\bm{F}</span> and <span class="math inline">x_j\in X</span> implies <span class="math inline">\alpha_j = 0</span> for all <span class="math inline">j</span>. Note that the empty set is independent.</p>
<p><strong>Exercise</strong>. <em>If <span class="math inline">X</span> is independent and <span class="math inline">\sum_j \alpha_j x_j = \sum_j \beta_j x_j</span> where <span class="math inline">\alpha_j,\beta_j\in\bm{F}</span> and <span class="math inline">x_j\in X</span> show <span class="math inline">\alpha_j = \beta_j</span> for all <span class="math inline">j</span></em>.</p>
<p>Independence ensures unique representations of linear combinations.</p>
<p>If <span class="math inline">\sum_j \alpha_j x_j = 0</span> and <span class="math inline">\alpha_k\not = 0</span> for some <span class="math inline">k</span> then <span class="math inline">x_k = -(1/\alpha_k)\sum_{j\not=k} \alpha_j x_j</span> is a linear combination of vectors in <span class="math inline">X\setminus \{x_k\}</span>. In this case <span class="math inline">X</span> is <em>linearly dependent</em> and <span class="math inline">X\setminus\{x_k\}</span> has the same span as <span class="math inline">X</span>. We use <em>reverse solidus</em> for <span class="math inline">A\setminus B = \{x\in A: x\notin B\}</span> for <em>set difference</em>.</p>
<p><strong>Exercise</strong>. <em>If <span class="math inline">X\subseteq V</span> is independent and <span class="math inline">y\not\in\vee X</span> show <span class="math inline">X\cup\{y\}</span> is independent</em>.</p>
<p>Let <span class="math inline">\mathcal{C}</span> be a collection of independent subsets of <span class="math inline">V</span> that is totally ordered by inclusion, that is, given <span class="math inline">X,Y\in\mathcal{C}</span> either <span class="math inline">X\subseteq Y</span> or <span class="math inline">Y\subseteq X</span>.</p>
<p><strong>Exercise</strong>. <em>Show <span class="math inline">\cup\mathcal{C} = \cup_{X\in\mathcal{C}} X</span> is independent</em>.</p>
<p>A <em>basis</em> of <span class="math inline">V</span> is an independent set <span class="math inline">X\subseteq V</span> that spans <span class="math inline">V</span>.</p>
<p><strong>Exercise</strong>. <em>Prove every vector space has a basis</em>.</p>
<p>Hint: Use the previous exercises and Zorn’s lemma.</p>
<h3 id="dimension">Dimension</h3>
<p>The <em>dimension</em> of <span class="math inline">V</span> is the cardinality of a basis <span class="math inline">X</span> for <span class="math inline">V</span>. A fundamental fact about vector spaces is that every basis has the same cardinality. This is necessary to show the definition of dimension is well-defined.</p>
<p>If <span class="math inline">X\subseteq V</span> is a basis of <span class="math inline">V</span> then every <span class="math inline">v\in V</span> can be uniquely written as a finite linear combination <span class="math inline">v = \sum_j \alpha_j x_j</span> for some <span class="math inline">\alpha_j\in\bm{F}</span> and <span class="math inline">x_j\in X</span>. This defines a map <span class="math inline">J_X\colon V\to c_{00}(X)</span> where <span class="math inline">J_X v(x) = \alpha_j</span> if and only if <span class="math inline">x = x_j</span>.</p>
<p><strong>Exercise</strong>. <em>Show <span class="math inline">J_X</span> is an isomorphism if <span class="math inline">X</span> is a basis</em>.</p>
<p>This shows for any basis <span class="math inline">X</span> of <span class="math inline">V</span> that <span class="math inline">V\cong c_{00}(X)</span>.</p>
<p>If <span class="math inline">s\colon X\to Y</span> is any function from the set <span class="math inline">X</span> to the set <span class="math inline">Y</span> define <span class="math inline">S\colon c_{00}(X)\to c_{00}(Y)</span> by <span class="math inline">S(\sum_j \alpha_j x_j) = \sum_j \alpha_j s(x_j)</span>.</p>
<p><strong>Exercise</strong>. <em>Show <span class="math inline">S</span> is linear for any function <span class="math inline">s</span></em>.</p>
<p>Every linear transformation <span class="math inline">S\colon c_{00}(X)\to c_{00}(Y)</span> induces a function <span class="math inline">s\colon X\to Y</span> by <span class="math inline">s(x) = S(\delta_x) = ???</span>.</p>
<p><strong>Exercise</strong>. <em>Show <span class="math inline">S</span> is injective if and only if <span class="math inline">s</span> is injective</em>.</p>
<p><strong>Exercise</strong>. <em>Show <span class="math inline">S</span> is surjective if and only if <span class="math inline">s</span> is surjective</em>.</p>
<p><strong>Exercise</strong>. <em>Show <span class="math inline">S</span> is an isomorphism if and only if <span class="math inline">X</span> and <span class="math inline">Y</span> have the same cardinality</em>.</p>
<p>This shows that if <span class="math inline">X</span> and <span class="math inline">Y</span> are basis’ of <span class="math inline">V</span> then <span class="math inline">c_{00}(X) \cong V \cong c_{00}(Y)</span>. We conclude <span class="math inline">X</span> and <span class="math inline">Y</span> have the same cardinality so dimension is well-defined.</p>
<p>In classical linear algebra texts this fact is proved using the Steinitz exchange lemma when the vector spaces are finite dimensional. The proof above works for vector spaces of any dimension.</p>
<h3 id="quotient-space">Quotient Space</h3>
<p>Every subspace <span class="math inline">U</span> of <span class="math inline">V</span> determines an equivalence relation on <span class="math inline">V</span> by <span class="math inline">x\sim y</span> if and only if <span class="math inline">x - y\in U</span>.</p>
<p><strong>Exercise</strong>. <em>Show <span class="math inline">\sim</span> is an equivalence relation</em>.</p>
<p>For any <span class="math inline">x\in V</span> let <span class="math inline">x + U = \{x + u:u\in U\}</span>.</p>
<p><strong>Exercise</strong>. <em>Show <span class="math inline">x + U = y + U</span> if and only if <span class="math inline">x\sim y</span> for <span class="math inline">x,y\in V</span></em>.</p>
<p>This shows <span class="math inline">x + U</span> can be identified with the coset of <span class="math inline">x</span> under this equivalence relation.</p>
<p>If <span class="math inline">U</span> is a subspace of <span class="math inline">V</span> we define the <em>quotient space</em> <span class="math inline">V/U = \{x + U:x\in V\}</span>.</p>
<p>Define quotient space addition by <span class="math inline">(x + U) + (y + U) = (x + y) + U</span> and scalar multiplication by <span class="math inline">\alpha (x + U) = \alpha x + U</span>.</p>
<p><strong>Exercise</strong>. <em>Show quotient space addition and scalar multiplication are well-defined</em>.</p>
<p><strong>Exercise</strong>. <em>Show the quotient space is a vector space</em>.</p>
<p>???</p>
<p>Quotient spaces split vector spaces into two <em>complementary</em> vector spaces.</p>
<p>For <span class="math inline">U</span> a subspace of <span class="math inline">V</span> define <span class="math inline">J:U\to V</span> by inclusion, <span class="math inline">Ju = u</span>, so <span class="math inline">\operatorname{ran}J = U</span>.</p>
<p><span class="math inline">v = u + w</span> where <span class="math inline">u\in U</span>.</p>
<p><span class="math inline">u\mapsto u \oplus (v - u) + U</span></p>
<h4 id="sum">Sum</h4>
<p>The <em>external sum</em> of vector spaces <span class="math inline">U</span> and <span class="math inline">W</span>, <span class="math inline">U\oplus W</span>, is the set <span class="math inline">U\times W</span> with addition <span class="math inline">(u,w) + (x, y) = (u + x, w + y)</span>, where <span class="math inline">u,x\in U</span> and <span class="math inline">w,y\in W</span>, and scalar multiplication <span class="math inline">\alpha (u, w) = (\alpha u, \alpha w)</span> for <span class="math inline">\alpha \in\bm{F}</span>. The external sum addition and scalar multiplication on the left-hand sides are defined in terms of those for <span class="math inline">U</span> and <span class="math inline">W</span> in the first and second elements (respectively) of the pairs on the right-hand sides.</p>
<p>Instead of <span class="math inline">(u,w)</span> it is customary to write <span class="math inline">u\oplus w</span>. The definitions above become <span class="math inline">(u\oplus w) + (x\oplus y) = (u + x)\oplus(w + y)</span> and <span class="math inline">\alpha (u\oplus w) = \alpha u\oplus \alpha w</span>.</p>
<p><strong>Exercise</strong>. <em>Show the external sum is a vector space</em>.</p>
<p>Every vector space <span class="math inline">V</span> is <em>isomorphic</em> to the external sum of <span class="math inline">U</span> and <span class="math inline">V/U</span> for any subspace <span class="math inline">U\subseteq V</span>, but we have to define isomorphic in terms of invertible <em>linear transformations</em> between vector spaces.</p>
<p>If <span class="math inline">U\subseteq V</span> is a subspace then <span class="math inline">V\cong U\oplus V/U</span>. Define <span class="math inline">I_U\colon U\oplus V/U\to V</span> by <span class="math inline">u\oplus v+U\mapsto u + v</span>.</p>
<strong>Exercise</strong>. <em>Show this is well-defined</em>.
<details>
<p><summary>Solution</summary></p>
<blockquote>
<p>If <span class="math inline">I_U u \oplus v + U = 0</span> then <span class="math inline">u + v = 0</span>. Since <span class="math inline">v = -u\in U</span> we have <span class="math inline">v + U = 0 + U</span>.</p>
</blockquote>
</details>
<h4 id="internal">Internal</h4>
<p>If <span class="math inline">U</span> and <span class="math inline">W</span> are subspaces of <span class="math inline">V</span> then <span class="math inline">U + W</span> is also as subspace of <span class="math inline">V</span>. If <span class="math inline">U\cap W = \{0\}</span> it is called an <em>interal sum</em>.</p>
<p><strong>Exercise</strong>. <em>Let <span class="math inline">U</span> and <span class="math inline">W</span> be subspaces of <span class="math inline">V</span> with <span class="math inline">U\cap W = \{0\}</span>. If <span class="math inline">u + w = u&#39; + w&#39;</span> with <span class="math inline">u,u&#39;\in U</span> and <span class="math inline">w,w&#39;\in W</span> show <span class="math inline">u = u&#39;</span> and <span class="math inline">w = w&#39;</span></em>.</p>
<p><em>Hint</em>. <span class="math inline">u - u&#39;\in U</span> and <span class="math inline">w&#39; - w\in W</span>.</p>
<p>This shows every vector <span class="math inline">v\in U + W</span> has a unique decomposition <span class="math inline">v = u + w</span> with <span class="math inline">u\in U</span> and <span class="math inline">w\in W</span> when <span class="math inline">U\cap W = \{0\}</span>.</p>
<p><strong>Exercise</strong>. <em>If <span class="math inline">X\subseteq V</span> is independent and <span class="math inline">T\in\mathcal{L}(V,W)</span> is injective then <span class="math inline">TX\subseteq W</span> is independent</em>.</p>
<p><strong>Exercise</strong>. <em>If <span class="math inline">T</span> is surjective and the span of <span class="math inline">X\subseteq V</span> is <span class="math inline">V</span> show the span of <span class="math inline">TX</span> is <span class="math inline">W</span></em>.</p>
<p>If <span class="math inline">T</span> is both one-to-one and onto (injective and surjective) it is an <em>isomorphism</em> between <span class="math inline">V</span> and <span class="math inline">W</span>. Its <em>inverse</em> is <span class="math inline">T^{-1}\colon W\to V</span> where <span class="math inline">T^{-1}w = v</span> if and only if <span class="math inline">Tv = w</span> for <span class="math inline">v\in V</span> and <span class="math inline">w\in W</span>.</p>
<p><strong>Exercise</strong>. <em>Show the inverse of a linear transformation is linear</em>.</p>
<p>Isomorphisms induce an equivalence relation on vector spaces. We write <span class="math inline">V\cong W</span> to indicate <span class="math inline">V</span> is isomorphic to <span class="math inline">W</span>.</p>
<p><strong>Exercise</strong>. Show <span class="math inline">V\cong V</span>, if <span class="math inline">V\cong W</span> then <span class="math inline">W\cong V</span>, and if <span class="math inline">U\cong V</span> and <span class="math inline">V\cong W</span> then <span class="math inline">U\cong W</span>.</p>
<p><em>Hint</em>: Isomorphisms are invertable.</p>
<p>Every <span class="math inline">T\in\mathcal{L}(V,W)</span> factors through <span class="math inline">V/\ker T</span> and <span class="math inline">\operatorname{ran}T</span>. There are linear transformations <span class="math inline">V\to V/\ker T\to \operatorname{ran}T\to W</span>. The first, <span class="math inline">V\to V/\ker T</span>, sends <span class="math inline">v\mapsto v + \ker T</span>, the second, <span class="math inline">V/\ker T\to\operatorname{ran}T</span>, sends <span class="math inline">v + \ker T\mapsto Tv</span>, and the third, <span class="math inline">\operatorname{ran}T\to W</span>, is just inclusion <span class="math inline">Tv\mapsto Tv\in W</span>.</p>
<p>We already know <span class="math inline">(x + U) + (y + U) = (x + y) + U</span> and <span class="math inline">\alpha (x + U) = \alpha x + U</span> for any subspace <span class="math inline">U</span> so the first map is linear.</p>
<p><strong>Exercise</strong>. <em>Show <span class="math inline">V\to V/\ker T</span> where <span class="math inline">v\mapsto + V/\ker T</span> is surjective</em>.</p>
<p><strong>Exercise</strong>. <em>Show if <span class="math inline">x + \ker T = y + \ker T</span> then <span class="math inline">Tx = Ty</span>.</em></p>
<p>This shows the second map is well-defined.</p>
<p><strong>Exercise</strong>. <em>Show second map <span class="math inline">V/\ker T\to\operatorname{ran}T</span> is injective</em>.</p>
<p><strong>Exercise</strong>. <em>Show second map <span class="math inline">V/\ker T\to\operatorname{ran}T</span> is surjective</em>.</p>
<p>This show <span class="math inline">V/\ker T \cong \operatorname{ran}T</span>.</p>
<p>???We can now show <span class="math inline">V</span> is isomorphic to the external sum of <span class="math inline">U</span> and <span class="math inline">V/U</span> for any subspace <span class="math inline">U\subseteq V</span>.</p>
<p>For <span class="math inline">v\in V</span> and <span class="math inline">u\in U</span> <span class="math inline">v = u + (v - u)</span>. Define <span class="math inline">J</span> by…</p>
<p><strong>Exercise</strong>. <em>Show <span class="math inline">J</span> is surjective</em>.</p>
<p><strong>Exercise</strong>. <em>Show <span class="math inline">J</span> is injective</em>.</p>
<h3 id="endomorphisms">Endomorphisms</h3>
<p>The endomorphisms <span class="math inline">\mathcal{L}(V)</span> are more than just a vector space. They have a <em>product</em> defined by composition <span class="math inline">(ST)x = S(Tx)</span> for <span class="math inline">S,T\in\mathcal{L}(V)</span> and <span class="math inline">x\in V</span>. This makes them a <em>ring</em>. Recall a ring is a vector space with a product that satisfies</p>
<dl>
<dt><em>Associative</em></dt>
<dd><span class="math inline">R(ST) = (RS)T</span>
</dd>
<dt><em>Identity</em></dt>
<dd>There is a multiplicative identity <span class="math inline">I</span> with <span class="math inline">IR = R</span>
</dd>
<dt><em>Distibutive</em></dt>
<dd><span class="math inline">R(S + T) = RS + RT</span>
</dd>
</dl>
<p>Composition of linear transformations is associative, the identity is <span class="math inline">Ix = x</span> for <span class="math inline">x\in V</span>, and the distibutive law follows from linearity <span class="math inline">R(S+T)x = R(Sx + Tx) = RSx + RTx = (RS + TS)x</span>.</p>
<p>The integers are the prototypical example of a ring. The set of polynomials in one variable <span class="math inline">\bm{F}[t] = \{p(t) = \sum_{n\ge0} \alpha_n t^n\}</span>, where <span class="math inline">\alpha _n\in\bm{F}</span> is a ring.</p>
<p>For any endomorphism <span class="math inline">T\in\mathcal{V}</span> there is a <em>functional calculus</em> <span class="math inline">\Phi_T\colon\bm{F}[t]\to\mathcal{F}(V)</span> defined by <span class="math inline">p(t)\mapsto p(T)</span> that preserves the ring structure.</p>
<p>Note: If we replace the requirement that the scalars are a field by the requirement they are a ring we have a <em>module</em> instead of a vector space. Modules are not (by a long shot) characterized by their dimension.</p>
<p>If <span class="math inline">R\in\mathcal{L}(c_{00}(X), c_{00}(Y))</span> and <span class="math inline">S\in\mathcal{L}(c_{00}(Y), c_{00}(Z))</span>, then <span class="math inline">SR\in\mathcal{L}(c_{00}(X), c_{00}(Z))</span>.</p>
<p><strong>Exercise</strong>. <em>Show <span class="math inline">(SR)(\delta_x) = \sum_{y\in Y} R(\delta_x) S(\delta_j)</span></em>.</p>
<p>Composition is matrix multiplication.</p>
<h3 id="dual-space">Dual Space</h3>
<p>The <em>dual vector space</em> of the vector space <span class="math inline">V</span> is the space of <em>linear functionals</em> <span class="math inline">V^* = \mathcal{L}(V,\bm{F})</span>. For <span class="math inline">v\in V</span> and <span class="math inline">v^*\in V^*</span> we write the <em>dual pairing</em> <span class="math inline">\langle v, v^*\rangle = v^*(v)\in\bm{F}</span>.</p>
<p>Obviously, if <span class="math inline">x^*,y^*\in V^*</span> then <span class="math inline">\langle v,x^*\rangle = \langle v,y^*\rangle</span> for all <span class="math inline">v\in V</span> implies <span class="math inline">x^* = y^*</span>.</p>
<p><strong>Exercise</strong>. <em>Show if <span class="math inline">x,y\in V</span> and <span class="math inline">\langle x,v^*\rangle = \langle y,v^*\rangle</span> for all <span class="math inline">v^*\in V^*</span> then <span class="math inline">x = y</span></em>.</p>
<p><em>Hint</em>. Show if <span class="math inline">\langle v,v^*\rangle = 0</span> for all <span class="math inline">v^*\in V^*</span> then <span class="math inline">v = 0</span>.</p>
<p>For any subset <span class="math inline">X\subseteq V</span> the <em>annihilator</em> is <span class="math inline">X^\perp = \{x^*\in V^*: \langle x, x^*\rangle = 0, x\in X\}\subseteq V^*</span>.</p>
<p><strong>Exercise</strong>. <em>The annihilator of any <span class="math inline">X\subseteq V</span> is a subspace of <span class="math inline">V^*</span></em>.</p>
<p>For any subset <span class="math inline">X^*\subseteq V^*</span> the <em>preannihilator</em> is <span class="math inline">^\perp X^* = \{x\in V: \langle x, x^*\rangle = 0, x^*\in X^*\}\subseteq V</span>.</p>
<p><strong>Exercise</strong>. <em>The preannihilator of any <span class="math inline">X^*\subseteq V^*</span> is a subspace of <span class="math inline">V</span></em>.</p>
<p><strong>Exercise</strong>. <em>For any <span class="math inline">X\subseteq V</span> <span class="math inline">^\perp(X^\perp)</span> is the span of <span class="math inline">X</span></em>.</p>
<p><strong>Exercise</strong>. <em>For any <span class="math inline">X^*\subseteq V^*</span> <span class="math inline">(^\perp X^*)^\perp</span> is the span of <span class="math inline">X^*</span></em>.</p>
<p>For <span class="math inline">T\in\mathcal{L}(V, W)</span> the <em>adjoint</em> <span class="math inline">T^*\in\mathcal{L}(W^*, V^*)</span> is defined by <span class="math inline">\langle Tv, w^*\rangle = \langle v, T^*w^*\rangle</span> for <span class="math inline">v\in V</span> and <span class="math inline">w^*\in W^*</span>.</p>
<h2 id="normed-space">Normed Space</h2>
<p>A <em>normed vector space</em> is a vector space with a <em>norm</em> <span class="math inline">\|.\|\colon V\to [0,\infty)</span> where <span class="math inline">\|x + y\| \le \|x\| + \|y\|</span>, <span class="math inline">\|\alpha x\| = |\alpha|\|x\|</span>, and <span class="math inline">\|x\| = 0</span> implies <span class="math inline">x = 0</span>, <span class="math inline">\alpha\in\bm{F}</span>, <span class="math inline">x,y\in V</span>. It provides a <em>metric</em> on <span class="math inline">V</span> by <span class="math inline">d(x,y) = \|x - y\|</span>.</p>
<p><strong>Exercies</strong>. <em>Show <span class="math inline">d</span> is a metric</em>.</p>
<p>If a normed space is <em>complete</em> in this topology it is called a <em>Banach space</em>. We use <span class="math inline">X</span>, <span class="math inline">Y</span>, for vector spaces that are Banach spaces.</p>
<p>If the norm on <span class="math inline">V</span> does not satisfy <span class="math inline">\|x\| = 0</span> implies <span class="math inline">x = 0</span> we say the norm is <em>singular</em>. We can mod out by <em>null</em> vectors to get a non-singular norm.</p>
<p><strong>Exercise</strong>. <em>If <span class="math inline">W</span> is a subspace of a (possibly singular) normed space <span class="math inline">V</span> show <span class="math inline">\|v + W\| = \inf_{w\in W}\|v + w\|</span> is a (possibly singular) norm on <span class="math inline">V/W</span></em>.</p>
<p><strong>Exercise</strong>. <em>Show <span class="math inline">Z = \{x\in V\colon \|x\| = 0\}</span> is a subspace of <span class="math inline">V</span> and <span class="math inline">\|x + Z\| = 0</span> implies <span class="math inline">x + Z = 0 + Z</span> in <span class="math inline">V/Z</span></em>.</p>
<p>Every normed space can be <em>completed</em> into a Banach space. Let <span class="math inline">V^\NN = \{x\colon\NN\to V\} = \{(x_n)_{n\in\NN}:x_n\in V\}</span> be the set of all sequences of vectors in <span class="math inline">V</span>. Recall <span class="math inline">(x_n)_{n\in\NN}</span> is a <em>Cauchy sequence</em> if given <span class="math inline">\epsilon &gt; 0</span> there exists <span class="math inline">N\in\NN</span> with <span class="math inline">d(x_n, x_m) = \|x_n - x_m\| &lt; \epsilon</span> whenever <span class="math inline">m,n &gt; N</span>.</p>
<p><strong>Exercise</strong>. <em>Let <span class="math inline">C</span> be the collection of Cauchy sequences in <span class="math inline">V^\NN</span> where <span class="math inline">V</span> is a normed space. Define <span class="math inline">x \sim y</span> if <span class="math inline">\lim_n x_n = \lim_n y_n</span>, <span class="math inline">x,y\in C</span>. Show this is an equivalence relation and <span class="math inline">\bar{V} = C/\sim</span> is a Banach space</em>.</p>
<p><strong>Exercise</strong>. <em>Let <span class="math inline">C_V</span> be the collection of constant sequences in <span class="math inline">V^\NN</span> where <span class="math inline">V</span> is a normed space. Show <span class="math inline">C_V/\sim</span> is dense in <span class="math inline">C/\sim</span></em>.</p>
<p>The space of linear transformations between normed spaces has a norm. Define <span class="math inline">\|T\| = \sup_{\|x\|\le 1}\|Tx\|</span> for <span class="math inline">\mathcal{L}(V, W)</span> if both <span class="math inline">V</span> and <span class="math inline">W</span> are normed.</p>
<p>A linear transformation is <em>bounded</em> if <span class="math inline">\|T\| &lt; \infty</span> for <span class="math inline">T\in\mathcal{L}(V,W)</span>. The bounded linear transformations are denoted <span class="math inline">\mathcal{B}(V,W)</span>. In this case we call them <em>linear operators</em> or simply <em>operators</em>.</p>
<p><strong>Exercise</strong>. <em>Show this is a norm on <span class="math inline">\mathcal{B}(V,W)</span></em>.</p>
<p><strong>Exercise</strong>. <em>Show <span class="math inline">\mathcal{B}(V,W)</span> is a subspace of <span class="math inline">\mathcal{L}(V,W)</span></em>.</p>
<p>Bounded operators are continuous.</p>
<p><strong>Exercise</strong>. <em>Show if <span class="math inline">T\in\mathcal{B}(V,W)</span> then <span class="math inline">Tx_n \to 0</span> in <span class="math inline">W</span> as <span class="math inline">x_n\to 0</span> in <span class="math inline">V</span></em>.</p>
<p>Continuous operators are bounded.</p>
<p>A convenient way of showing an operator is bounded is</p>
<p><strong>Exercise</strong>. <em>Show if <span class="math inline">T</span> is continuous then <span class="math inline">T</span> is bounded</em>.</p>
<p><strong>Theorem</strong>. (Uniform Boundedness Priciple, Banach-Steinhous) <em>For <span class="math inline">T_n\in\mathcal{B}(V,W)</span>, <span class="math inline">\{\|T_nx\|\}</span> is bounded all <span class="math inline">x\in V</span> implies <span class="math inline">\{\|T_n\|\}</span> is bounded</em>.</p>
<p>This is a theorem because the proof is non-trivial. It relies on the Baire Category Theorem for complete metric spaces. (The intersection of a countable collection of open dense sets is dense.)</p>
<p><strong>Theorem</strong>. (Open Mapping Theorem) <em>The image of the unit ball under a surjective operator contains an open ball centered at the origin</em>.</p>
<p>The <em>graph</em> of a linear transformation <span class="math inline">T\in\mathcal{L}(V,W)</span> is the set <span class="math inline">\{(x, Tx):x\in V\}\subseteq V\times W</span>.</p>
<p><strong>Theorem</strong>. (Closed Graph Theorem) <em>An operator is continuous if and only if its graph is closed</em>.</p>
<h3 id="examples">Examples</h3>
<p>For any set <span class="math inline">I</span> the set of all functions from <span class="math inline">I</span> to a field <span class="math inline">\bm{F}</span> is <span class="math inline">\bm{F}^I = \{x\colon I\to\bm{F}\}</span>. It is a vector space, the <em>free vector space</em> on <span class="math inline">I</span>, and has a basis <span class="math inline">\{e_i\}_{i\in I}</span> where <span class="math inline">e_i(i) = 1</span> and <span class="math inline">e_i(j) = 0</span> for <span class="math inline">j\not=i</span>. This is not a normed space.</p>
<p>The vectors <span class="math inline">x\in\bm{F}^I</span> with <span class="math inline">\|x\|_\infty = \sup_{i\in I}|x(i)| &lt; \infty</span> are the Banach space <span class="math inline">\mathcal{l}^\infty(I)</span>.</p>
<p>If <span class="math inline">I</span> is totally ordered (or a net) define the Banach spaces <span class="math inline">c(I) = \{x\in\bm{F}^I:\lim_i x(i) \mathrm{\ exists}\}</span> and <span class="math inline">c_0(I) = \{x\in\bm{F}^I:\lim_i x(i) = 0\}</span>.</p>
<p>Clearly <span class="math inline">c_0 \subseteq c \subseteq \mathcal{l}^\infty</span>.</p>
<p>The vectors with <span class="math inline">\|x\|_1 = \sum_{i\in I}|x(i)| &lt; \infty</span> are the Banach space <span class="math inline">\mathcal{l}^1(I)</span>. More generally vectors with <span class="math inline">\|x\|_p = \bigl(\sum_{i\in I}|x(i)|^p\bigr)^{1/p} &lt; \infty</span> define the Banach space <span class="math inline">\mathcal{l}^p(I)</span>, <span class="math inline">1\le p &lt; \infty</span>.</p>
<p><strong>Exercise</strong>. <em>Show if <span class="math inline">x\in\mathcal{l}^\infty</span> then <span class="math inline">x\in\mathcal{l}^p</span> for <span class="math inline">1\le p &lt; \infty</span> and <span class="math inline">\lim_{p\to\infty}\|x\|_p = \|x\|_\infty</span></em>.</p>
<p>If <span class="math inline">I</span> is equipped with a positive measure <span class="math inline">\mu</span> we can similarly define <span class="math inline">L^p(\mu)</span> using <span class="math inline">\|f\|_p = \bigl(\int_I |f|^p\,d\mu\bigr)^{1/p}</span>.</p>
<p>The case when <span class="math inline">p = 2</span> is special.</p>
<h2 id="inner-product-space">Inner Product Space</h2>
<p>A function <span class="math inline">(.,.)\colon V\times V\to\bm{F}</span> with <span class="math inline">y\mapsto (x,y)</span> and <span class="math inline">y\mapsto (y,x)</span> linear in <span class="math inline">y</span> for each <span class="math inline">x\in V</span> is a <em>bilinear</em> function. If also <span class="math inline">(\alpha x,y) = (x, \bar{\alpha } y)</span> for <span class="math inline">\alpha \in\bm{F}</span> and <span class="math inline">x,y\in V</span> it is <em>sesquilinear</em>. An <em>inner product</em> on a vector space V is a <em>sesquilinear</em> form that is also <em>non-singular</em>, <span class="math inline">(x, x) = 0</span> implies <span class="math inline">x = 0</span>.</p>
<p><strong>Exercise</strong>. <em>If the inner product is singular then <span class="math inline">K = \{x:(x,x) = 0\}</span> is a subspace of <span class="math inline">V</span>. The inner product on <span class="math inline">V/K</span> defined by <span class="math inline">(x + K, y + K) = (x, y)</span> is well-defined and non-singular</em>.</p>
<p>The <em>norm</em> of a vector is <span class="math inline">\|x\| = \sqrt{(x,x)}</span>. The Cauchy-Schwartz inequality is <span class="math inline">|(x,y)|\le\|x\| \|y\|</span> with equality if and only if <span class="math inline">x</span> and <span class="math inline">y</span> are linearly dependent. This follows from <span class="math inline">0\le \|x - \lambda y\|^2 = \|x\|^2 - 2\Re \lambda (x, y) + |\lambda|^2\|y\|^2</span> and taking <span class="math inline">\lambda = (x,y)/\|y\|^2</span>. Equality holds if and only if <span class="math inline">x = \lambda y</span>.</p>
<p>If <span class="math inline">T\in\mathcal{L}(V,V^*)</span> then <span class="math inline">(x,y) = \langle x, Ty\rangle</span> is bilinear.</p>
<h3 id="eigenvectors">Eigenvectors</h3>
<p>Every operator on a finite dimensional inner product space has an eigenvector. The set <span class="math inline">\{Tx:\|x\|=1\}</span> is closed and bounded so there exists a unit vector <span class="math inline">e</span> with <span class="math inline">x = Te</span> and <span class="math inline">|\|Tx\|\ge\|Ty\|</span> for all unit vectors <span class="math inline">y</span>. Since <span class="math inline">\|x|\^2 = (Te, x) \le \|Te\| \|x\| = \|x\|^2</span> we have <span class="math inline">Te = \lambda x</span> for some scalar <span class="math inline">\lambda</span> since equality holds in the Cauchy-Schwartz inequality.</p>
<p>Not every operator on an infinite dimensional inner product space has an eigenvector. Define the <em>unilateral shift operator</em> <span class="math inline">S\colon\mathcal{l}^2\to\mathcal{l}^2</span> by <span class="math inline">S(x_0, x_1, \ldots) = (0, x_0, x_1, \dots)</span>. If <span class="math inline">Sx = \lambda x</span> then <span class="math inline">0 = \lambda x_0</span>, <span class="math inline">x_1 = \lambda x_0</span>, , so <span class="math inline">x = 0</span>.</p>
<p>The unilateral shift does have lots of invariant subspaces however. If the first <span class="math inline">m</span> components of <span class="math inline">x</span> are zero then the first <span class="math inline">m+1</span> components of <span class="math inline">Sx</span> are zero so <span class="math inline">\mathcal{M}_m = \{x\in\mathcal{l}^2:x_j = 0, j &lt; m\}</span> are invariant for all <span class="math inline">m</span>.</p>
<p><strong>Exercise</strong>. <em>Show <span class="math inline">\mathcal{M}_m</span> is a subspace of <span class="math inline">\mathcal{l}^2</span></em>.</p>
<p>The <em>unilateral backward shift operator</em> is the adjoint of <span class="math inline">S</span>.</p>
<p><strong>Exercise</strong>. <em>Show <span class="math inline">(S^*x)_j = x_{j + 1}</span> for <span class="math inline">j\ge 0</span></em>.</p>
<p><strong>Exercise</strong>. <em>Show <span class="math inline">x = (1,0,0,\ldots)</span> is an eigenvector with eigenvalue 0</em>.</p>
<p><strong>Exercise</strong>. _Show <span class="math inline">\mathcal{M}_n^\perp = \{x\in\mathcal{l}^2:x_j = 0, j \ge m\}</span> is an invariant subspace of <span class="math inline">S^*</span>.</p>
<p>All invariant subspaces of the unilateral shift operator are characterized by a theorem of Arne Beurling.</p>
<h2 id="eigenvector-eigenvalue">Eigenvector, Eigenvalue</h2>
<p>If <span class="math inline">Tv = \lambda v</span> for some $$ then <span class="math inline">\lambda</span> is an <em>eigenvalue</em> of <span class="math inline">T</span> and <span class="math inline">v</span> is its corresponding <em>eigenvector</em>. If <span class="math inline">I</span> is the <em>identity operator</em> defined by <span class="math inline">Iv = v</span> for all <span class="math inline">v</span> and <span class="math inline">\lambda</span> is an eigenvalue, then <span class="math inline">T - \lambda I</span> is not invertable since <span class="math inline">(T - \lambda I)v = 0</span>.</p>
<p>If the eigenvectors of <span class="math inline">T</span> are independent … And form a basis… Then <span class="math inline">Tv_i = \lambda_i vi_i</span> and <span class="math inline">TV = \sum \lambda_i v_i</span>. We say <span class="math inline">T</span> is <em>diagonalizable</em>.</p>
<p>If <span class="math inline">T</span> has only one eigenvalue… (Jordan form)</p>
<p><strong>Theorem</strong>. If <span class="math inline">V</span> is finite dimensional every operator in <span class="math inline">\mathcal{L}(V)</span> has an eigenvector.</p>
<p>If <span class="math inline">T\in\mathcal{L}(V)</span> and <span class="math inline">Tx = 0</span> for some <span class="math inline">x\in V</span> then <span class="math inline">x</span> is an eigenvector with eigenvalue <span class="math inline">0</span></p>
<p>If <span class="math inline">(x,y) = \|x\| \|y\|</span> then <span class="math inline">\alpha x = y</span> for some <span class="math inline">\alpha \in\bm{F}</span>.</p>
<p>There exists <span class="math inline">x^*</span> such that <span class="math inline">\|x*\| \ge \|T e\|</span> for <span class="math inline">\|e\| = 1</span>.</p>
<h2 id="polynomial-functional-calculus">Polynomial Functional Calculus</h2>
<p>Let <span class="math inline">\bm{F}[t]</span> be the <em>ring</em> of polynomials in the variable <span class="math inline">t</span> over the scalar field <span class="math inline">\bm{F}</span>. Define <span class="math inline">\Phi\bm{F}[t]\to \mathcal{L}(V)</span> by <span class="math inline">\Phi(p) = p(T)</span> where <span class="math inline">p(t) = \sum_{n\ge0} \alpha_n t^n</span>.</p>
<p><strong>Exercise</strong>. <em>Show <span class="math inline">\Phi</span> is a ring homomorphism</em>.</p>
<h1 id="remarks">Remarks</h1>
<p><span class="math inline">I\supset R</span>, <span class="math inline">R&#39; = R</span>, <span class="math inline">R^2\subseteq R</span>.</p>
<p>Infinite sums. What does <span class="math inline">\sum_{x\in X} \alpha_x x</span> for <span class="math inline">\alpha_x\in\bm{F}</span> mean? Define <span class="math inline">+\colon \bm{F}^I\times V^I\to V</span> for any <span class="math inline">I</span> as follows: … We introduce <span class="math inline">I</span> since the scalars and vectors must be indexed by the same set. We are really defining <span class="math inline">+\colon 2^V\times\bm{F}^I\times V^I\to V</span>…</p>
<p>[Grobner basis…]</p>
</body>
</html>
