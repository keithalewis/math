---
title: First Order Logic
---
\newcommand\implies{\rightarrow}
\newcommand\nor{\downarrow}
\newcommand\nand{\uparrow}
\newcommand\and{\wedge}
\newcommand\or{\vee}

Everything in classical mathematics is expressed in terms of first order
logic. FOL extends propositional calculus by adding statements that
can be quantification over propositions parameterized by variables.
There are many logics aside from first-order predicate logic but they all share the
notion that a proof of 'If $P$ then $Q$' starts with the proposition '$P$'
and uses the axioms and rules of inference for that logic to produce '$Q$'.
More precisely, the proof demonstrates that assuming $P$ is true then $Q$ is true.
More compactly, we also say $P$ _implies_ $Q$ and write $P\implies Q$.

A logic is _sound_ if the axioms and rules of inference cannot be used
to produce a false statement. A logic is _complete_ if every
true statement can be proved using the axioms and rules of inference.
A logic is not _consistent_ if a statement and its negation can be proved.
A logic is _decidable_ if there is an algorithm to prove every true statement.

syntax vs semantics

If this makes you think a proof is similar to a computation
[Curry and Howard](@howard1980curryhoward)
beat you to it. Howard noticed the axiom system

1. $x\implies(y\implies x)$
2. $x\implies (y \implies z)\implies((x\implies y)\implies(x\implies z))$

was in one-to-one correspondence with the $\lambda$-calculus combinators

1. $Kxy = x$
2. $Sxyz = xy(xz)$


## Predicate

Mathematicians use a vocabulary even more impoverished than that of a sailor.
Proposition logic uses the words _not_, _and_, _or_, and _implies_.
The mathematical symbols for these words are $\neg$, $\and$, $\or$,
and $\implies$. If $P$ is a proposition then $\neg P$ is true if $P$ is false and
$\neg P$ is false if $P$ is true. The words 'and' and 'or' have
the usual meaning. The odd man out is 'implies'.

The mathematical definition of $P$ implies $Q$ is not $P$ or $Q$,
so ${P\implies Q}$ is defined as ${(\neg P)\or Q}$.

__Exercise__. _Show $P$ implies $Q$ is true if $P$ is false_.

You would not be the only one to think this is a bit odd.  Mathematicians
must use common words to define things. The choice of the word 'implies' should not be
construed to mean $P$ 'causes' $Q$.

__Exercise__. _Show if $P$ is true and $P\implies Q$ is true then $Q$ is true_.

We say $P$ and $Q$ are _equivalent_ if $P\equiv Q$ is true if and only if
$P$ and $Q$ are both $P$ and $Q$ are true or both $P$ and $Q$ are false.

The symbol $\equiv$ indicates a _tautology_. For any values of
$P$ and $Q$ both sides are either both true or both false.

New words can be defined it terms of these.

For example we define _equivalent_ by 


All of these word can be defined in terms of _nand_, the negation of _and_,
$P\nand Q \equiv \neg(P\and Q)$.

__Exercise__, _Show $\neg P \equiv P\nand P$_.

_Hint_: If $P$ is true then $P$ and $P$ is true.
If $P$ is false then $P$ and $P$ is false.

__Exercise__. _Show $P\and Q \equiv \neg(P\nand Q)$_.

_Hint_: That is the definition of nand.

__Exercise__. _Show $P\or Q \equiv \neg(\neg P \and \neg Q)$._.

### Well-Formed

Here is the recipe for all _well-formed formulas_.

1. A proposition is a WFF.

2. If $\phi$ is a WFF then $\neg \phi$ is a WFF.

3. If $\phi$ and $\psi$ are WFFs then $\phi\nand \psi$ is a WFF.

We use lower-case Greek letters for WFFs built from these rules.

We use parentheses to indicate the order in which the rules were applied.
For example, $\neg P \nand Q$ could be either
$(\neg P)\nand Q$ (apply rule 2 to $P$ and rule 3 to that and $Q$)
or $\neg(P\nand Q)$ (apply rule 3 to $P$ and $Q$ then rule 2 to that).

<details><summary>Polish Notation</summary>
We can avoid parenthesis by assuming negation applies to the next valid WWF
and nand applies to the next two WWFs.
For example $\nand\neg P Q$ is $(\neg P)\nand Q$
and $\neg\nand P Q$ is $\neg(P\nand Q)$.
</details>

### Proofs

One way to establish a tautology is to evaluate both sides for
all possible truth values of propositions.
If there are $n$ propositions on each side then $2^n$ calculations
are required.

A more parsimonious approach is to posit _axioms_ and use _rules of inference_.
The axioms of propositional logic are

1. $\phi\implies(\psi\implies\phi)$
2. $\phi\implies(\psi\implies\chi)\implies((\phi\implies\psi)\implies(\phi\implies\chi))$
3. $(\neg\psi\implies\neg\phi)\implies(\phi\implies\psi)$

The only rule of inference is _modus ponens_ (a means to advance)
that from $\phi$ and $\phi\implies\psi$ we can infer $\psi$.
A proof of $\phi\implies\psi$ consists of starting with $\phi$ we
can use axioms and modus ponens to infer $\psi$.

<details><summary>Tableau</summary>
Raymond Smullyan...
</details>

## Boolean Algebra

George Boole showed how to reduce propositional logic to algebraic equations,
thus laying the foundation for computer science.
Given a set $S$ we can consider the algebra of functions from subsets of $S$
to $\{0,1\}$. Given $\{P\colon S\to\{0, 1\}}}$ define $1_P(s) = 1$ if $s\in P$
and $1_P(s) = 0$ if $s\not\in P$.






## First Order

In _first order logic_ propositions can be parameterized variables.
